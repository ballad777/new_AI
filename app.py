"""
ğŸ¤– ä¼æ¥­ç´š AI æ™ºèƒ½æ•¸æ“šåˆ†æç³»çµ± v16.1
================================================================
ä¸‰å¼•æ“æ¶æ§‹: æ•¸æ“šæ¸…æ´— Â· èªæ„æ„ŸçŸ¥ Â· é‚è¼¯å¤§è…¦
v16.1 å¾®èª¿ä¿®å¾©:
  âœ… è·¨å¹´ä»½æ¯”è¼ƒåœ–è¡¨ä¿®å¾©ï¼ˆæœˆä»½è»¸ + å¹´ä»½åˆ†è‰²ï¼‰
  âœ… å´é‚Šæ¬„ UI å¼·åŒ–ï¼ˆå±•é–‹ç‹€æ…‹ + æŒ‰éˆ•å„ªåŒ–ï¼‰
  
ç¹¼æ‰¿ v15.0 æ ¸å¿ƒ:
  âœ… ASP æ­£ç¢ºå…¬å¼: æœªç¨…æ·¨é¡/æ·¨æ•¸é‡ï¼ˆç¦ç”¨å«ç¨…ï¼‰
  âœ… å„ªå…ˆä½¿ç”¨ã€Œå«æ­£è² è™Ÿã€æ¬„ä½ï¼ˆç³»çµ±åŸç”Ÿæ·¨é¡ï¼‰
  âœ… éŠ·é€€è‡ªå‹•è½‰è²  + ç¦æ­¢é‡è¤‡æ‰£é™¤
  âœ… æŸ¥ç„¡è³‡æ–™å›å ±æ©Ÿåˆ¶
  âœ… åœ–è¡¨å¼·åˆ¶è§¸ç™¼ï¼ˆOne-Shot Chartingï¼‰
  âœ… èªæ„æ¬„ä½åµæ¸¬ï¼ˆå–®åˆ¥â‰ å“åï¼‰
================================================================
"""

import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from openai import OpenAI
import json
import re
from typing import Dict, List, Optional, Tuple, Any
import numpy as np
import io
import traceback

# ============================================================================
# å…¨åŸŸé…ç½®
# ============================================================================
PASSWORD = "0413"
EMBEDDED_API_KEY = st.secrets["OPENAI_API_KEY"]
PAGE_TITLE = "ğŸ¤– AI æ™ºèƒ½æ•¸æ“šåˆ†æå¸«"
PAGE_ICON = "ğŸ¤–"
GPT_MODEL = "gpt-4o"
MAX_RETRIES = 3
TEMPERATURE = 0.01

COLOR_PALETTE = {
    'default': ['#FF6B35', '#004E89', '#2ECC71', '#9B59B6', '#F39C12',
                '#1ABC9C', '#E74C3C', '#3498DB', '#E91E63', '#00BCD4'],
    'blue': ['#004E89', '#0066B3', '#3498DB', '#5DADE2', '#85C1E9', '#AED6F1'],
    'red': ['#E74C3C', '#C0392B', '#F1948A', '#EC7063', '#CD6155', '#F5B7B1'],
    'green': ['#2ECC71', '#27AE60', '#58D68D', '#82E0AA', '#ABEBC6', '#D5F5E3'],
    'orange': ['#FF6B35', '#E67E22', '#F39C12', '#F8C471', '#FAD7A0', '#FDEBD0'],
    'purple': ['#9B59B6', '#8E44AD', '#BB8FCE', '#D2B4DE', '#E8DAEF', '#F4ECF7'],
    'rainbow': ['#E74C3C', '#E67E22', '#F1C40F', '#2ECC71', '#3498DB', '#9B59B6', '#1ABC9C'],
    'pastel': ['#FFB3BA', '#FFDFBA', '#FFFFBA', '#BAFFC9', '#BAE1FF', '#E0BBE4'],
    'dark': ['#2C3E50', '#34495E', '#7F8C8D', '#95A5A6', '#BDC3C7'],
    'warm': ['#E74C3C', '#E67E22', '#F39C12', '#D35400', '#C0392B'],
    'cool': ['#3498DB', '#2980B9', '#1ABC9C', '#16A085', '#2ECC71', '#00BCD4'],
}

COLOR_NAME_MAP = {
    'è—': 'blue', 'è—è‰²': 'blue', 'blue': 'blue',
    'ç´…': 'red', 'ç´…è‰²': 'red', 'red': 'red',
    'ç¶ ': 'green', 'ç¶ è‰²': 'green', 'green': 'green',
    'æ©™': 'orange', 'æ©™è‰²': 'orange', 'orange': 'orange', 'æ©˜': 'orange', 'æ©˜è‰²': 'orange',
    'ç´«': 'purple', 'ç´«è‰²': 'purple', 'purple': 'purple',
    'é»ƒ': 'orange', 'é»ƒè‰²': 'orange',
    'å½©è™¹': 'rainbow', 'å¤šå½©': 'rainbow', 'rainbow': 'rainbow',
    'æŸ”å’Œ': 'pastel', 'ç²‰å½©': 'pastel', 'pastel': 'pastel',
    'æ·±è‰²': 'dark', 'æš—è‰²': 'dark', 'dark': 'dark',
    'æš–è‰²': 'warm', 'warm': 'warm',
    'å†·è‰²': 'cool', 'cool': 'cool',
}

CHART_TYPE_MAP = {
    'é•·æ¢åœ–': 'bar', 'æŸ±ç‹€åœ–': 'bar', 'ç›´æ¢åœ–': 'bar', 'bar': 'bar',
    'åˆ†çµ„é•·æ¢åœ–': 'grouped_bar', 'åˆ†çµ„': 'grouped_bar', 'ä¸¦æ’': 'grouped_bar',
    'grouped_bar': 'grouped_bar',
    'å †ç–Šé•·æ¢åœ–': 'stacked_bar', 'å †ç–Š': 'stacked_bar', 'stacked_bar': 'stacked_bar',
    'æŠ˜ç·šåœ–': 'line', 'ç·šåœ–': 'line', 'è¶¨å‹¢åœ–': 'line', 'line': 'line',
    'é¢ç©åœ–': 'area', 'area': 'area',
    'å †ç–Šé¢ç©åœ–': 'stacked_area', 'stacked_area': 'stacked_area',
    'åœ“é¤…åœ–': 'pie', 'é¤…åœ–': 'pie', 'pie': 'pie',
    'ç’°å½¢åœ–': 'donut', 'ç”œç”œåœˆ': 'donut', 'donut': 'donut',
    'æ•£é»åœ–': 'scatter', 'scatter': 'scatter',
    'æ°´å¹³é•·æ¢åœ–': 'horizontal_bar', 'æ°´å¹³': 'horizontal_bar', 'æ©«æ¢åœ–': 'horizontal_bar',
    'horizontal_bar': 'horizontal_bar',
    'ç€‘å¸ƒåœ–': 'waterfall', 'waterfall': 'waterfall',
    'æ¼æ–—åœ–': 'funnel', 'funnel': 'funnel',
    'é›·é”åœ–': 'radar', 'radar': 'radar',
    'ç†±åŠ›åœ–': 'heatmap', 'heatmap': 'heatmap',
    'æ¨¹ç‹€åœ–': 'treemap', 'treemap': 'treemap',
    'æ—­æ—¥åœ–': 'sunburst', 'sunburst': 'sunburst',
}

CUSTOM_CSS = """
<style>
    .main-header {
        background: linear-gradient(135deg, #FF6B35 0%, #004E89 50%, #2ECC71 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        font-size: 2.8rem; font-weight: 800; text-align: center; margin-bottom: 0.5rem;
    }
    .sub-header { text-align: center; color: #666; font-size: 1.05rem; margin-bottom: 2rem; }
    .data-header {
        background: linear-gradient(90deg, #FF6B35 0%, #FF8F6B 100%);
        color: white; padding: 0.8rem 1.2rem; border-radius: 10px 10px 0 0;
        font-weight: 700; font-size: 1.05rem;
    }
    .thinking-box {
        background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
        border-left: 5px solid #3498DB; border-radius: 0 10px 10px 0;
        padding: 1.2rem 1.5rem; margin: 1rem 0; font-size: 0.95rem;
        color: #2C3E50; line-height: 1.6;
    }
    .engine-report {
        background: linear-gradient(135deg, #f0fdf4 0%, #dcfce7 100%);
        border-left: 5px solid #16a34a; border-radius: 0 10px 10px 0;
        padding: 1rem 1.2rem; margin: 0.5rem 0; font-size: 0.88rem; line-height: 1.7;
    }
    .sheet-badge {
        display: inline-block;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white; padding: 0.3rem 0.8rem; border-radius: 15px;
        font-size: 0.85rem; margin: 0.2rem; font-weight: 600;
    }
    #MainMenu {visibility: hidden;} 
    footer {visibility: hidden;}
    /* ä¿ç•™ Streamlit çš„ header ä»¥é¡¯ç¤ºå´é‚Šæ¬„å±•é–‹æŒ‰éˆ• */
    header[data-testid="stHeader"] {
        background-color: transparent;
    }
    /* ç¢ºä¿å´é‚Šæ¬„æ§åˆ¶æŒ‰éˆ•å¯è¦‹ */
    button[kind="header"] {
        visibility: visible !important;
    }
    [data-testid="collapsedControl"] {
        visibility: visible !important;
        display: block !important;
    }
    .stButton > button {
        border-radius: 10px; font-weight: 600; transition: all 0.3s ease;
    }
    .stButton > button:hover {
        transform: translateY(-2px); box-shadow: 0 5px 20px rgba(0,0,0,0.15);
    }
    /* å´é‚Šæ¬„æŒ‰éˆ•çµ±ä¸€å°ºå¯¸ */
    [data-testid="stSidebar"] .stButton > button {
        min-height: 38px;
        padding: 0.4rem 0.5rem;
        font-size: 0.85rem;
    }
    /* å¼·åŒ–å´é‚Šæ¬„å±•é–‹æŒ‰éˆ•çš„å¯è¦‹åº¦ */
    [data-testid="collapsedControl"] {
        background: linear-gradient(135deg, #FF6B35 0%, #004E89 100%) !important;
        color: white !important;
        border-radius: 0 8px 8px 0 !important;
        padding: 12px 6px !important;
        box-shadow: 2px 2px 10px rgba(0,0,0,0.3) !important;
        transition: all 0.3s ease !important;
    }
    [data-testid="collapsedControl"]:hover {
        transform: translateX(3px) !important;
        box-shadow: 3px 3px 15px rgba(0,0,0,0.4) !important;
    }
    [data-testid="collapsedControl"] svg {
        width: 24px !important;
        height: 24px !important;
        color: white !important;
    }
</style>
"""

# ============================================================================
# å®‰å…¨å·¥å…·
# ============================================================================
def safe_get_string(value, default=''):
    if value is None: return default
    if isinstance(value, str): return value
    if isinstance(value, (list, tuple)): return str(value[0]) if value else default
    return str(value)

def format_number(x):
    try:
        if pd.isna(x): return ''
        if isinstance(x, (int, float, np.integer, np.floating)):
            return f"{x:,.0f}" if abs(x) >= 1 else f"{x:.2f}"
        return str(x)
    except Exception:
        return str(x)


# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘  ENGINE 1: æ•¸æ“šæ¸…æ´—å¼•æ“                                      â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
class DataCleaningEngine:
    SUMMARY_KW = ['ç¸½è¡¨', 'å½™ç¸½', 'summary', 'total', 'åˆè¨ˆ', 'çµ±è¨ˆ']
    DETAIL_KW = ['æ˜ç´°', 'äº¤æ˜“', 'detail', 'raw', 'transaction', 'éŠ·è²¨', 'é€²è²¨', 'å‡ºè²¨']
    RETURN_KW = ['éŠ·é€€', 'é€€è²¨', 'é€€å›', 'return', 'credit', 'æŠ˜è®“', 'refund', 'éŠ·æŠ˜']
    TYPE_KW = ['å–®åˆ¥', 'å–®æ“šé¡å‹', 'type', 'å–®åˆ¥åç¨±']
    NUMERIC_KW = ['æ•¸é‡', 'é‡‘é¡', 'qty', 'amt', 'æœªç¨…', 'å«ç¨…', 'ç¨…é¡', 'å–®åƒ¹',
                  'price', 'amount', 'total', 'cost', 'æˆæœ¬', 'ç‡Ÿæ”¶', 'revenue',
                  'æ¯›åˆ©', 'profit', 'æ·¨é¡', 'åº«å­˜', 'quantity', 'è²»ç”¨']
    ID_KW = ['id', 'ç·¨è™Ÿ', 'åºè™Ÿ', 'no', 'code', 'ä»£è™Ÿ', 'sku', 'å–®è™Ÿ',
             'number', 'é›»è©±', 'æµæ°´è™Ÿ']
    DATE_KW = ['æ—¥æœŸ', 'date', 'æ™‚é–“']
    SKIP_SHEET_KW = ['index', 'readme', 'èªªæ˜', 'template']
    SAFE_DEDUP_COLS = ['å”¯ä¸€æµæ°´è™Ÿ(å­æª”)', 'åºè™Ÿ', 'æµæ°´è™Ÿ']

    def __init__(self):
        self.log = []
        self.stats = {}
        self._reset()

    def _reset(self):
        self.log = []
        self.stats = dict(total_files=0, total_sheets_read=0,
                          sheets_skipped_summary=0, sheets_skipped_other=0,
                          rows_before_dedup=0, rows_after_dedup=0,
                          duplicates_removed=0, dedup_strategy='',
                          return_rows_negated=0, return_type_col='',
                          numeric_cols_standardized=0, date_cols_processed=0)

    def _m(self, text, keywords):
        t = text.strip().lower()
        return any(k in t for k in keywords)

    # â”€â”€ ä¸»æµç¨‹ â”€â”€
    def clean(self, files, selected_sheets=None):
        self._reset()
        frames = []
        meta = dict(files=[], sheets=[], total_rows=0, columns=[],
                    numeric_columns=[], date_columns=[], categorical_columns=[],
                    years=[], sample_data={}, unique_values={},
                    load_errors=[], data_summary={})

        for f in files:
            self.stats['total_files'] += 1
            try:
                fb = f.read(); f.seek(0)
                xls = pd.ExcelFile(io.BytesIO(fb))
                fname = f.name
                to_load = self._resolve_sheets(xls.sheet_names, fname, selected_sheets)
                for sn in to_load:
                    df_s = self._load_sheet(xls, sn, fname)
                    if df_s is not None and len(df_s) > 0:
                        frames.append(df_s)
                        meta['sheets'].append(dict(file=fname, sheet=sn, rows=len(df_s),
                                                   columns=[c for c in df_s.columns if not str(c).startswith('_')]))
                        self.stats['total_sheets_read'] += 1
                        self.log.append(f"âœ… [{fname}] â†’ '{sn}' ({len(df_s):,} è¡Œ)")
                meta['files'].append(fname)
            except Exception as e:
                meta['load_errors'].append(f"{f.name}: {e}")
                self.log.append(f"âŒ {f.name}: {e}")

        if not frames:
            return None, meta, self.stats

        combined = pd.concat(frames, ignore_index=True, sort=False)
        self.stats['rows_before_dedup'] = len(combined)

        combined = self._safe_dedup(combined)
        combined = self._standardize_numeric(combined)
        combined = self._negate_returns(combined)
        combined = self._convert_dates(combined)
        self._finalize_meta(combined, meta)
        self.log.append(f"ğŸ¯ æ¸…æ´—å®Œç•¢: {len(combined):,} è¡Œ Ã— {len(combined.columns)} æ¬„")
        return combined, meta, self.stats

    def _resolve_sheets(self, names, fname, selected):
        if selected and fname in selected:
            return selected[fname]
        valid = [s for s in names if not self._m(s, self.SKIP_SHEET_KW)]
        if not valid:
            valid = names
        has_sum = any(self._m(s, self.SUMMARY_KW) for s in valid)
        has_det = any(self._m(s, self.DETAIL_KW) for s in valid)
        if has_sum and has_det:
            kept = []
            for s in valid:
                if self._m(s, self.SUMMARY_KW):
                    self.stats['sheets_skipped_summary'] += 1
                    self.log.append(f"ğŸš« æ™ºæ…§è·¯ç”±ä¸Ÿæ£„ç¸½è¡¨: [{fname}] â†’ '{s}'")
                else:
                    kept.append(s)
            return kept
        return valid

    def _load_sheet(self, xls, sheet, fname):
        try:
            raw = pd.read_excel(xls, sheet_name=sheet, header=None, nrows=15)
            if raw.empty: return None
            hr = self._detect_header(raw)
            df = pd.read_excel(xls, sheet_name=sheet, header=hr)
            df.columns = [str(c).strip() for c in df.columns]
            df = df.loc[:, ~df.columns.str.contains('^Unnamed', na=False)]
            df.dropna(how='all', inplace=True)
            if len(df) == 0: return None
            df['_ä¾†æºæª”æ¡ˆ'] = fname
            df['_å·¥ä½œè¡¨'] = sheet
            return df
        except Exception:
            return None

    def _detect_header(self, raw):
        for i in range(min(10, len(raw))):
            row = raw.iloc[i]
            v = sum(1 for val in row if pd.notna(val) and isinstance(val, str)
                    and len(str(val).strip()) > 0
                    and not str(val).strip().replace('.','').replace('-','').replace('/','').isdigit())
            if v >= max(3, len(row) * 0.3):
                return i
        return 0

    def _safe_dedup(self, df):
        for sc in self.SAFE_DEDUP_COLS:
            if sc in df.columns:
                b = len(df)
                df = df.drop_duplicates(subset=[sc], keep='first').reset_index(drop=True)
                r = b - len(df)
                self.stats.update(rows_after_dedup=len(df), duplicates_removed=r,
                                  dedup_strategy=f"åŸºæ–¼: {sc}")
                if r > 0: self.log.append(f"ğŸ—‘ï¸ å®‰å…¨å»é‡({sc}): -{r:,}")
                return df

        key_cols = [c for c in ['æ—¥æœŸ(è½‰æ›)', 'é€²éŠ·å–®è™Ÿ', 'ç”¢å“ä»£è™Ÿ', 'æ•¸é‡'] if c in df.columns]
        if len(key_cols) >= 2:
            b = len(df)
            df = df.drop_duplicates(subset=key_cols, keep='first').reset_index(drop=True)
            r = b - len(df)
            self.stats.update(rows_after_dedup=len(df), duplicates_removed=r,
                              dedup_strategy=f"åŸºæ–¼: {', '.join(key_cols)}")
            if r > 0: self.log.append(f"ğŸ—‘ï¸ çµ„åˆå»é‡: -{r:,}")
        else:
            uc = [c for c in df.columns if not str(c).startswith('_')]
            b = len(df)
            df = df.drop_duplicates(subset=uc, keep='first').reset_index(drop=True)
            r = b - len(df)
            self.stats.update(rows_after_dedup=len(df), duplicates_removed=r,
                              dedup_strategy="å…¨æ¬„ä½å»é‡")
            if r > 0: self.log.append(f"ğŸ—‘ï¸ å…¨æ¬„ä½å»é‡: -{r:,}")
        return df

    def _standardize_numeric(self, df):
        cnt = 0
        for col in df.columns:
            if str(col).startswith('_'): continue
            if self._m(col, self.NUMERIC_KW) and not self._m(col, self.ID_KW):
                try:
                    if df[col].dtype == 'object':
                        df[col] = df[col].astype(str).str.replace(',','',regex=False)\
                            .str.replace('$','',regex=False).str.replace('NT','',regex=False)\
                            .str.replace('ï¿¥','',regex=False).str.strip()
                    df[col] = pd.to_numeric(df[col], errors='coerce')
                    cnt += 1
                except Exception: pass
        self.stats['numeric_cols_standardized'] = cnt
        if cnt > 0: self.log.append(f"ğŸ”¢ æ•¸å€¼æ¨™æº–åŒ–: {cnt} æ¬„")
        return df

    def _negate_returns(self, df):
        signed = [c for c in df.columns if 'æ­£è² è™Ÿ' in str(c) or 'net' in str(c).lower()]
        if signed:
            self.log.append(f"â„¹ï¸ å·²æœ‰æ­£è² è™Ÿæ¬„ä½ {signed}ï¼Œè·³ééŠ·é€€è½‰è² ")
            return df
        type_cols = [c for c in df.columns if self._m(c, self.TYPE_KW) and not str(c).startswith('_')]
        if not type_cols:
            self.log.append("â„¹ï¸ ç„¡å–®åˆ¥æ¬„ä½ï¼Œè·³ééŠ·é€€è½‰è² ")
            return df
        num_cols = [c for c in df.columns
                    if self._m(c, self.NUMERIC_KW) and not self._m(c, self.ID_KW)
                    and not str(c).startswith('_') and pd.api.types.is_numeric_dtype(df[c])]
        if not num_cols: return df

        total = 0
        for tc in type_cols:
            mask = df[tc].apply(lambda v: False if pd.isna(v) else self._m(str(v), self.RETURN_KW))
            n = mask.sum()
            if n > 0:
                for nc in num_cols:
                    df.loc[mask, nc] = -df.loc[mask, nc].abs()
                total += n
                self.stats['return_type_col'] = tc
                self.log.append(f"ğŸ”„ éŠ·é€€è½‰è² : '{tc}' {n:,} ç­† â†’ {len(num_cols)} å€‹æ•¸å€¼æ¬„ä½å–è² ")
        self.stats['return_rows_negated'] = total
        return df

    def _convert_dates(self, df):
        cnt = 0
        for col in df.columns:
            if str(col).startswith('_'): continue
            if self._m(col, self.DATE_KW):
                try:
                    df[col] = pd.to_datetime(df[col], errors='coerce')
                    cnt += 1
                except Exception: pass
        if 'æ—¥æœŸ(è½‰æ›)' in df.columns:
            try:
                df['æ—¥æœŸ(è½‰æ›)'] = pd.to_datetime(df['æ—¥æœŸ(è½‰æ›)'], errors='coerce')
                df['_å¹´ä»½'] = df['æ—¥æœŸ(è½‰æ›)'].dt.year.astype('Int64')
                df['_æœˆä»½'] = df['æ—¥æœŸ(è½‰æ›)'].dt.month.astype('Int64')
                df['_å­£åº¦'] = df['æ—¥æœŸ(è½‰æ›)'].dt.quarter.astype('Int64')
                df['_å¹´æœˆ'] = df['æ—¥æœŸ(è½‰æ›)'].dt.strftime('%Y-%m')
                cnt += 1
                self.log.append("ğŸ“… æ—¥æœŸæ¨™æº–åŒ–: æ—¥æœŸ(è½‰æ›) â†’ _å¹´ä»½/_æœˆä»½/_å­£åº¦/_å¹´æœˆ")
            except Exception:
                try:
                    p = pd.to_datetime(df['æ—¥æœŸ(è½‰æ›)'], errors='coerce')
                    df['_å¹´ä»½'] = p.dt.year; df['_æœˆä»½'] = p.dt.month
                except Exception: pass
        if '_å¹´ä»½' not in df.columns:
            for col in df.columns:
                if self._m(col, self.DATE_KW) and not str(col).startswith('_'):
                    if pd.api.types.is_datetime64_any_dtype(df[col]):
                        df['_å¹´ä»½'] = df[col].dt.year.astype('Int64')
                        df['_æœˆä»½'] = df[col].dt.month.astype('Int64')
                        df['_å¹´æœˆ'] = df[col].dt.strftime('%Y-%m')
                        break
        self.stats['date_cols_processed'] = cnt
        return df

    def _finalize_meta(self, df, meta):
        meta['total_rows'] = len(df)
        meta['columns'] = [c for c in df.columns if not str(c).startswith('_')]
        for col in df.columns:
            if str(col).startswith('_'): continue
            if pd.api.types.is_numeric_dtype(df[col]):
                meta['numeric_columns'].append(col)
            elif pd.api.types.is_datetime64_any_dtype(df[col]):
                meta['date_columns'].append(col)
            else:
                meta['categorical_columns'].append(col)
        if '_å¹´ä»½' in df.columns:
            try:
                meta['years'] = sorted([int(y) for y in df['_å¹´ä»½'].dropna().unique()])
            except Exception: pass
        for col in ['å°æ–¹å“å/å“åå‚™è¨»', 'ç”¢å“ä»£è™Ÿ', 'å®¢æˆ¶ä¾›æ‡‰å•†ç°¡ç¨±', 'å–®åˆ¥åç¨±', '_å·¥ä½œè¡¨']:
            if col in df.columns:
                try: meta['unique_values'][col] = df[col].dropna().unique().tolist()[:100]
                except Exception: pass
        for col in meta['columns'][:15]:
            try: meta['sample_data'][col] = df[col].dropna().head(5).tolist()
            except Exception: pass
        summary = {}
        if '_å·¥ä½œè¡¨' in df.columns:
            summary['sheet_distribution'] = df['_å·¥ä½œè¡¨'].value_counts().to_dict()
        if '_å¹´ä»½' in df.columns:
            summary['year_distribution'] = df['_å¹´ä»½'].value_counts().sort_index().to_dict()
        for col in meta['numeric_columns'][:5]:
            if col in df.columns:
                try:
                    summary[f'{col}_stats'] = dict(
                        sum=float(df[col].sum()), mean=float(df[col].mean()),
                        min=float(df[col].min()), max=float(df[col].max()))
                except Exception: pass
        meta['data_summary'] = summary


# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘  ENGINE 2: èªæ„æ„ŸçŸ¥æ¨¡çµ„                                       â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
class SemanticDetectionModule:
    def audit(self, df, meta):
        cols = [c for c in df.columns if not str(c).startswith('_')]
        signed_cols = [c for c in cols if 'æ­£è² è™Ÿ' in c or 'å«æ­£è² ' in c]
        a = dict(
            product_name_cols=self._names(cols),
            product_code_cols=self._codes(cols),
            date_cols=self._dates(cols),
            numeric_cols=meta.get('numeric_columns', []),
            type_cols=self._types(cols),
            customer_cols=self._custs(cols),
            has_signed_cols=signed_cols,
            qty_signed_col=self._find_col(signed_cols, ['æ•¸é‡']),
            amount_signed_col=self._find_col(signed_cols, ['é‡‘é¡', 'æœªç¨…']),
            amount_untaxed_col=self._find_col(cols, ['æœªç¨…é‡‘é¡', 'æœªç¨…']),
            amount_taxed_col=self._find_col(cols, ['å«ç¨…é‡‘é¡', 'å«ç¨…']),
            qty_col=self._find_col(cols, ['æ•¸é‡']),
        )
        a['summary_text'] = self._summary(a)
        return a

    def _find_col(self, cols, keywords):
        """æ‰¾ç¬¬ä¸€å€‹åŒ¹é…çš„æ¬„ä½å"""
        for c in cols:
            cl = c.lower()
            if any(k in cl for k in keywords):
                return c
        return None

    def _names(self, cols):
        nk = ['å“å', 'å‚™è¨»', 'name', 'description', 'å“é …', 'å•†å“']
        ek = ['ä»£è™Ÿ', 'code', 'id', 'sku', 'ç·¨è™Ÿ', 'è²¨è™Ÿ', 'å–®åˆ¥', 'é¡åˆ¥', 'type', 'é¡å‹']
        return [c for c in cols if any(k in c.lower() for k in nk) and not any(k in c.lower() for k in ek)]

    def _codes(self, cols):
        ck = ['ä»£è™Ÿ', 'code', 'sku', 'è²¨è™Ÿ', 'æ–™è™Ÿ']
        return [c for c in cols if any(k in c.lower() for k in ck)]

    def _dates(self, cols):
        dk = ['æ—¥æœŸ', 'date', 'æ™‚é–“']
        return [c for c in cols if any(k in c.lower() for k in dk)]

    def _types(self, cols):
        tk = ['å–®åˆ¥', 'é¡å‹', 'type', 'å–®åˆ¥åç¨±']
        return [c for c in cols if any(k in c.lower() for k in tk)]

    def _custs(self, cols):
        ck = ['å®¢æˆ¶', 'å» å•†', 'customer', 'vendor', 'ä¾›æ‡‰å•†', 'å…¬å¸', 'æ¥­å‹™']
        return [c for c in cols if any(k in c.lower() for k in ck)]

    def _summary(self, a):
        lines = [
            f"ğŸ“¦ ç”¢å“åç¨±æ¬„ä½: {a['product_name_cols'] or 'æœªåµæ¸¬'}",
            f"ğŸ·ï¸ ç”¢å“ä»£è™Ÿæ¬„ä½: {a['product_code_cols'] or 'æœªåµæ¸¬'}",
            f"ğŸ“… æ—¥æœŸæ¬„ä½: {a['date_cols'] or 'æœªåµæ¸¬'}",
            f"ğŸ’° æ•¸å€¼æ¬„ä½: {a['numeric_cols'][:8]}...",
            f"ğŸ“‹ å–®åˆ¥æ¬„ä½: {a['type_cols'] or 'æœªåµæ¸¬'}",
            f"ğŸ‘¤ å®¢æˆ¶æ¬„ä½: {a['customer_cols'] or 'æœªåµæ¸¬'}",
        ]
        if a.get('has_signed_cols'):
            lines.append(f"âœ… å«æ­£è² è™Ÿæ¬„ä½: {a['has_signed_cols']}")
        if a.get('qty_signed_col'):
            lines.append(f"ğŸ“Š æ·¨æ•¸é‡æ¬„ä½: {a['qty_signed_col']}")
        if a.get('amount_signed_col'):
            lines.append(f"ğŸ’µ æ·¨é‡‘é¡æ¬„ä½: {a['amount_signed_col']}")
        return '\n'.join(lines)


# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘  ENGINE 3: é‚è¼¯å¤§è…¦å±¤                                        â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
class LogicalBrainEngine:
    def __init__(self, api_key):
        self.client = OpenAI(api_key=api_key)
        self.model = GPT_MODEL

    def _schema(self, df, meta):
        p = []
        p.append(f"## è³‡æ–™: {len(df):,} ç­†, å¹´ä»½: {meta.get('years',[])}, æª”æ¡ˆ: {meta.get('files',[])}, å·¥ä½œè¡¨: {len(meta.get('sheets',[]))} å€‹")
        if meta.get('data_summary',{}).get('year_distribution'):
            p.append("\n## å¹´ä»½åˆ†å¸ƒ")
            for y, c in meta['data_summary']['year_distribution'].items():
                p.append(f"- {y}å¹´: {c:,} ç­†")
        p.append("\n## æ¬„ä½")
        for col in df.columns:
            if str(col).startswith('_') and col not in ['_å¹´ä»½','_æœˆä»½','_å­£åº¦','_å¹´æœˆ','_å·¥ä½œè¡¨']:
                continue
            try: dt, u = str(df[col].dtype), df[col].nunique()
            except: dt, u = '?', 0
            tag = ""
            if col == 'å°æ–¹å“å/å“åå‚™è¨»': tag = "â­[å“å-str.contains()]"
            elif col == 'ç”¢å“ä»£è™Ÿ': tag = "â­[ä»£è™Ÿ-è‹±æ•¸]"
            elif 'æ­£è² è™Ÿ' in str(col) or 'å«æ­£è² ' in str(col): tag = "â­â­[å·²å«æ­£è² è™Ÿ-å„ªå…ˆä½¿ç”¨!]"
            elif 'æœªç¨…' in str(col) and 'æ­£è² ' not in str(col): tag = "â­[æœªç¨…é‡‘é¡-ç®—ASPç”¨æ­¤æ¬„]"
            elif col in ('æ•¸é‡',): tag = "â­[æ•¸é‡-å¾Œç«¯å·²è½‰è² ]"
            elif 'å«ç¨…' in str(col): tag = "âš ï¸[å«ç¨…-ä¸è¦ç”¨ä¾†ç®—ASP]"
            elif 'é‡‘é¡' in str(col): tag = "â­[é‡‘é¡]"
            elif col == 'å®¢æˆ¶ä¾›æ‡‰å•†ç°¡ç¨±': tag = "â­[å®¢æˆ¶]"
            elif col == 'å–®åˆ¥åç¨±': tag = "â­[å–®åˆ¥-äº¤æ˜“é¡å‹,ä¸æ˜¯ç”¢å“å!]"
            elif col == '_å·¥ä½œè¡¨': tag = "â­[å·¥ä½œè¡¨ä¾†æº]"
            elif col == '_å¹´ä»½': tag = "[æ•´æ•¸]"
            p.append(f"- **{col}** ({dt}) {u:,}å”¯ä¸€å€¼ {tag}")
        p.append("\n### è¼”åŠ©æ¬„ä½: _å¹´ä»½(int), _æœˆä»½(int), _å­£åº¦(int), _å¹´æœˆ(str), _å·¥ä½œè¡¨(str)")
        if meta.get('unique_values'):
            p.append("\n## é‡è¦æ¬„ä½å€¼")
            for col, vals in meta['unique_values'].items():
                p.append(f"### {col} (å…±{len(vals)})\n```\n{vals[:20]}\n```")
        return '\n'.join(p)

    def _sysprompt(self, df, meta, audit, query):
        schema = self._schema(df, meta)
        nc = audit.get('product_name_cols', ['å°æ–¹å“å/å“åå‚™è¨»'])
        cc = audit.get('product_code_cols', ['ç”¢å“ä»£è™Ÿ'])
        cu = audit.get('customer_cols', ['å®¢æˆ¶ä¾›æ‡‰å•†ç°¡ç¨±'])
        tc = audit.get('type_cols', ['å–®åˆ¥åç¨±'])
        rc, rch = None, None
        for cn, ck in COLOR_NAME_MAP.items():
            if cn in query.lower(): rc = ck; break
        for cn, ct in CHART_TYPE_MAP.items():
            if cn in query.lower(): rch = ct; break

        # å®‰å…¨é˜²è­·ï¼štype_cols ä¸èƒ½æ··å…¥ name_cols
        type_col_set = set(tc)
        nc_safe = [c for c in nc if c not in type_col_set]
        if not nc_safe:
            for fb in ['å°æ–¹å“å/å“åå‚™è¨»', 'å“åå‚™è¨»', 'å“å', 'ç”¢å“åç¨±']:
                if fb in df.columns:
                    nc_safe = [fb]; break
            if not nc_safe:
                nc_safe = ['å°æ–¹å“å/å“åå‚™è¨»']

        name_col = nc_safe[0]
        code_col = cc[0] if cc else 'ç”¢å“ä»£è™Ÿ'
        cust_col = cu[0] if cu else 'å®¢æˆ¶ä¾›æ‡‰å•†ç°¡ç¨±'
        type_col = tc[0] if tc else 'å–®åˆ¥åç¨±'

        # åµæ¸¬æ­£è² è™Ÿæ¬„ä½
        qty_signed = audit.get('qty_signed_col', '')
        amt_signed = audit.get('amount_signed_col', '')
        amt_untaxed = audit.get('amount_untaxed_col', '')
        has_signed = bool(qty_signed or amt_signed)

        # æ±ºå®šæ·¨é¡/æ·¨é‡çš„ä½¿ç”¨æ¬„ä½
        if qty_signed:
            net_qty_expr = f"df['{qty_signed}']"
            net_qty_note = f"âœ… ä½¿ç”¨å·²å«æ­£è² è™Ÿæ¬„ä½ `{qty_signed}`"
        else:
            net_qty_expr = "df['æ•¸é‡']  # å¾Œç«¯å·²å°éŠ·é€€è½‰è² "
            net_qty_note = "âœ… å¾Œç«¯å·²å°‡éŠ·é€€æ•¸é‡è½‰ç‚ºè² æ•¸ï¼Œç›´æ¥ sum()"

        if amt_signed:
            net_amt_expr = f"df['{amt_signed}']"
            net_amt_note = f"âœ… ä½¿ç”¨å·²å«æ­£è² è™Ÿæ¬„ä½ `{amt_signed}`"
        elif amt_untaxed:
            net_amt_expr = f"df['{amt_untaxed}']  # å¾Œç«¯å·²å°éŠ·é€€è½‰è² "
            net_amt_note = f"âœ… ä½¿ç”¨æœªç¨…é‡‘é¡ `{amt_untaxed}`"
        else:
            net_amt_expr = "df['æœªç¨…é‡‘é¡']  # å¾Œç«¯å·²å°éŠ·é€€è½‰è² "
            net_amt_note = "âœ… å¾Œç«¯å·²å°‡éŠ·é€€é‡‘é¡è½‰ç‚ºè² æ•¸"

        return f"""ä½ æ˜¯ v16.1 ä¼æ¥­ç´šæ•¸æ“šåˆ†æ AIï¼Œæ“æœ‰æœƒè¨ˆé‚è¼¯èˆ‡è³‡æ–™è¦–è¦ºåŒ–å°ˆé•·ã€‚
è³‡æ–™ä¾†æºï¼šdfï¼ˆå·²é è¼‰å…¥ï¼Œå« _å¹´ä»½, _æœˆä»½, _å­£åº¦, _å¹´æœˆ, _å·¥ä½œè¡¨ è¼”åŠ©æ¬„ä½ï¼‰ã€‚

# ğŸ›¡ï¸ çµ•å°å®‰å…¨å”è­°ï¼ˆé•åå³å¤±æ•—ï¼‰
1. **ç¦æ­¢ import**ï¼šåš´ç¦ `import matplotlib`, `plt`, `pandas`ã€‚ç›´æ¥ç”¨ç’°å¢ƒä¸­çš„ pd, dfã€‚
2. **å®Œæ•´æ€§**ï¼šç¦æ­¢å¯« `# ...` çœç•¥è™Ÿã€‚ç¨‹å¼ç¢¼å¿…é ˆå®Œæ•´å¯åŸ·è¡Œã€‚
3. **ç¹ªåœ–**ï¼šä¸è¦è‡ªå·±ç•«åœ–ï¼ç”Ÿæˆ `chart_config` å­—å…¸å³å¯ï¼Œç³»çµ±æœƒè‡ªå‹•ç¹ªåœ–ã€‚
4. **å…¨é‡é‹ç®—**ï¼šå¿…é ˆè™•ç†å…¨éƒ¨ {len(df):,} è¡Œï¼Œç¦æ­¢ .head() æˆ– .sample() è¨ˆç®—ã€‚

# ğŸ“ æœƒè¨ˆé‹ç®—é‚è¼¯ï¼ˆæœ¬ç³»çµ±æ ¸å¿ƒ â€” é•åæœƒç®—éŒ¯ï¼ï¼‰

## 1. æ·¨é¡åŸå‰‡ (Net Amount Principle)
- **å…¬å¼ï¼š** Net = Sales - Returns
- **æ·¨æ•¸é‡ï¼š** {net_qty_note}
  - å–å€¼ï¼š`{net_qty_expr}`
- **æ·¨é‡‘é¡ï¼š** {net_amt_note}
  - å–å€¼ï¼š`{net_amt_expr}`
- âš ï¸ åš´ç¦å†å¯«é¡å¤–æ¸›æ³•é‚è¼¯ï¼ˆå¦‚ sales - returnsï¼‰ï¼Œå¦å‰‡é‡è¤‡æ‰£é™¤ï¼
- âš ï¸ åš´ç¦ä½¿ç”¨ã€Œå«ç¨…é‡‘é¡ã€è¨ˆç®—å¹³å‡å–®åƒ¹ï¼

## 2. å¹³å‡å–®åƒ¹ (ASP) å…¬å¼ â€” æœ€é‡è¦ï¼
- **æ­£ç¢ºï¼š** ASP = SUM(æœªç¨…æ·¨é¡) / SUM(æ·¨æ•¸é‡)
- **ç¨‹å¼ç¢¼ï¼š**
```python
net_amount = filtered['{amt_signed or amt_untaxed or "æœªç¨…é‡‘é¡"}'].sum()
net_qty = filtered['{qty_signed or "æ•¸é‡"}'].sum()
asp = net_amount / net_qty if net_qty != 0 else 0
```
- âŒ åš´ç¦ï¼š`å«ç¨…é‡‘é¡.sum() / æ•¸é‡.sum()` â†’ é€™æœƒç®—éŒ¯ï¼

## 3. ç”¢å“åˆ†é¡å®šç¾© (Product Taxonomy)
- **ç™¼æ³¡åˆ·**ï¼š`df['{name_col}'].str.contains('ç™¼æ³¡åˆ·', case=False, na=False)`
- **DIBé™¶ç“·åˆ·**ï¼š`(df['{code_col}'].str.startswith('DIB', na=False)) & (df['{name_col}'].str.contains('é™¶ç“·åˆ·', case=False, na=False))`
- **å…¶ä»–é™¶ç“·åˆ·**ï¼š`(~df['{code_col}'].str.startswith('DIB', na=False)) & (df['{name_col}'].str.contains('é™¶ç“·åˆ·', case=False, na=False))`

# â­â­â­ æ¬„ä½ç”¨é€”å°ç…§è¡¨ï¼ˆé•åå³éŒ¯ï¼‰â­â­â­

| è¦æŸ¥ä»€éº¼ | æ­£ç¢ºæ¬„ä½ | èªªæ˜ |
|----------|----------|------|
| ç”¢å“åç¨± (ç™¼æ³¡åˆ·/é™¶ç“·åˆ·) | `{name_col}` | str.contains() æ¨¡ç³Šæœå°‹ |
| ç”¢å“ä»£è™Ÿ (BFB-236/DIB-001) | `{code_col}` | ==, startswith |
| å®¢æˆ¶/å» å•† (è¯é€š/æ¬£èˆˆ) | `{cust_col}` | str.contains() |
| å–®åˆ¥/äº¤æ˜“é¡å‹ (éŠ·è²¨/éŠ·é€€) | `{type_col}` | âš ï¸ é€™æ˜¯äº¤æ˜“é¡å‹ï¼Œä¸æ˜¯ç”¢å“ï¼|
| æ·¨æ•¸é‡ | `{qty_signed or 'æ•¸é‡'}` | å·²å«æ­£è² è™Ÿæˆ–å¾Œç«¯å·²è½‰è²  |
| æ·¨é‡‘é¡(æœªç¨…) | `{amt_signed or amt_untaxed or 'æœªç¨…é‡‘é¡'}` | ç®— ASP å¿…é ˆç”¨æ­¤æ¬„ |

## ğŸš¨ çµ•å°ç¦æ­¢
- âŒ `df['{type_col}'].str.contains('ç™¼æ³¡åˆ·')` â†’ {type_col} æ˜¯äº¤æ˜“é¡å‹ï¼ä¸æ˜¯ç”¢å“ï¼
- âŒ `df['{code_col}'].str.contains('ç™¼æ³¡åˆ·')` â†’ ä»£è™Ÿæ¬„æ˜¯è‹±æ•¸ï¼Œä¸å«ä¸­æ–‡ï¼
- âŒ ç”¨ã€Œå«ç¨…é‡‘é¡ã€ç®— ASP
- âœ… `df['{name_col}'].str.contains('ç™¼æ³¡åˆ·', case=False, na=False)` â†’ æ­£ç¢ºï¼

## ğŸ“Š åœ–è¡¨è§¸ç™¼æ©Ÿåˆ¶ (One-Shot Charting)
- åªè¦å•é¡Œå« ['åœ–', 'chart', 'è¶¨å‹¢', 'ä½”æ¯”', 'åˆ†ä½ˆ', 'æ¯”ä¾‹', 'æ’å', 'top', 'pie', 'bar', 'line']ï¼š
  - `need_chart` **å¿…é ˆ** ç‚º `true`
  - **å¿…é ˆ** ç”Ÿæˆ `chart_config`
  - é™¤éæŸ¥ç„¡è³‡æ–™ (len(result_df)==0)

## ğŸ¨ è·¨å¹´ä»½æ¯”è¼ƒåœ–è¡¨è¦å‰‡ (Visual Fix v16.1) â€” æ¥µé‡è¦ï¼
âš ï¸ ç•¶ç”¨æˆ¶æ„åœ–ç‚ºã€Œæ¯”è¼ƒã€ã€ã€Œè¶¨å‹¢ã€ã€ã€ŒåŒæœŸã€ä¸”æ¶‰åŠ**å¤šå€‹å¹´ä»½**æ™‚ï¼š
### è¦å‰‡ï¼š
1. **X è»¸å¿…é ˆä½¿ç”¨ `_æœˆä»½` (1-12)**ï¼Œä¸è¦ç”¨ `_å¹´æœˆ` æˆ–æ™‚é–“é€£çºŒè»¸
2. **Color å¿…é ˆä½¿ç”¨ `_å¹´ä»½`**ï¼Œä¸”**å¿…é ˆå…ˆè½‰å­—ä¸²**ï¼š`df['_å¹´ä»½'].astype(str)`
   - âŒ éŒ¯èª¤ï¼š`color='_å¹´ä»½'` â†’ æœƒç•«æˆæ¼¸å±¤è‰²
   - âœ… æ­£ç¢ºï¼šå…ˆåš `df['å¹´ä»½(æ–‡å­—)'] = df['_å¹´ä»½'].astype(str)`ï¼Œç„¶å¾Œ `color='å¹´ä»½(æ–‡å­—)'`
3. **çµæœ**ï¼šå¤šæ¢ç·š/é•·æ¢æœƒç–ŠåŠ åœ¨åŒä¸€å€‹æœˆä»½è»¸ä¸Šï¼Œå¯é€²è¡ŒåŒæœŸæ¯”è¼ƒ

### ç¯„ä¾‹ï¼š2023-2025 ä¸‰å¹´åŒæœŸæ¯”è¼ƒ
```python
# ç¯©é¸å¤šå¹´è³‡æ–™
multi_year = df[df['_å¹´ä»½'].isin([2023, 2024, 2025])].copy()
multi_year['å¹´ä»½(æ–‡å­—)'] = multi_year['_å¹´ä»½'].astype(str)  # â­ é—œéµæ­¥é©Ÿ

# æŒ‰å¹´ä»½å’Œæœˆä»½åˆ†çµ„
result_df = multi_year.groupby(['_æœˆä»½', 'å¹´ä»½(æ–‡å­—)'])['æ•¸é‡'].sum().reset_index()
result_df.columns = ['æœˆä»½', 'å¹´ä»½', 'æ•¸é‡']
result_df = result_df.sort_values(['æœˆä»½', 'å¹´ä»½'])

# chart_config è¨­å®š
chart_config = {{
    'x': 'æœˆä»½',           # â­ ä½¿ç”¨æœˆä»½ (1-12)
    'y': 'æ•¸é‡',
    'color': 'å¹´ä»½',       # â­ ä½¿ç”¨å¹´ä»½(æ–‡å­—) ä½œç‚ºåˆ†é¡
    'title': '2023-2025å¹´ç™¼æ³¡åˆ·æœˆéŠ·é‡åŒæœŸæ¯”è¼ƒ'
}}
```

### ä½•æ™‚è§¸ç™¼æ­¤è¦å‰‡ï¼š
- å•é¡ŒåŒ…å«ï¼šã€Œæ¯”è¼ƒã€ã€ã€Œå°æ¯”ã€ã€ã€ŒåŒæœŸã€ã€ã€Œè¶¨å‹¢ã€ã€ã€Œvsã€ã€ã€Œç›¸æ¯”ã€
- ä¸”æ¶‰åŠï¼š2 å€‹ä»¥ä¸Šå¹´ä»½ (å¦‚ã€Œ2024 vs 2025ã€ã€ã€Œè¿‘ä¸‰å¹´ã€ã€ã€Œæ­·å¹´ã€)
- åœ–è¡¨é¡å‹ï¼šlineï¼ˆæŠ˜ç·šåœ–ï¼‰ã€barï¼ˆé•·æ¢åœ–ï¼‰ã€areaï¼ˆé¢ç©åœ–ï¼‰

## ğŸ” ç©ºçµæœè™•ç†
- ç•¶ç¯©é¸çµæœç‚ºç©º (len==0)ï¼š
  - answer å¿…é ˆå¯«ã€ŒğŸ” ç¶“æŸ¥è©¢ï¼Œè©²æ¢ä»¶ä¸‹ç„¡æ•¸æ“šè¨˜éŒ„ã€
  - need_chart è¨­ç‚º false
  - result_df è¨­ç‚ºç©º DataFrame åŠ ä¸Šèªªæ˜æ¬„

## â­ ç¯©é¸é˜²å‘†
- å•é¡Œå«ç‰¹å®šå¯¦é«” â†’ ç¬¬ä¸€æ­¥ target_df = df[condition]ï¼Œå†å° target_df è¨ˆç®—

{schema}

# ç”¨æˆ¶: {query}
# é¡è‰²: {rc or 'æœªæŒ‡å®š'}, åœ–è¡¨: {rch or 'AIæ±ºå®š'}

# ğŸ“¤ JSON æ ¼å¼
{{
  "answer": "åˆ†æçµè«–ï¼ˆè‹¥æŸ¥ç„¡è³‡æ–™è«‹æ˜ç¢ºå‘ŠçŸ¥ï¼‰ã€‚è«‹åŠ å…¥å•†æ¥­æ´å¯Ÿï¼Œä¸è¦åªçµ¦å†·å†°å†°çš„æ•¸å­—æè¿°ã€‚",
  "thinking": "1. ç¯©é¸æ¢ä»¶... 2. ä½¿ç”¨æ¬„ä½... 3. è¨ˆç®—é‚è¼¯...",
  "need_chart": true/false,
  "chart_type": "{rch or 'bar'}",
  "chart_color": "{rc or ''}",
  "code": "å®Œæ•´å¯åŸ·è¡Œçš„ Python ç¨‹å¼ç¢¼"
}}

# ğŸ’» ç¨‹å¼ç¢¼è¦ç¯„
- df å·²åœ¨ç’°å¢ƒä¸­ï¼Œresult_df = DataFrame, chart_config = dict
- ç¦æ­¢ import / matplotlib / plt
- chart_config çš„ x,y,color å¿…é ˆæ˜¯**å­—ä¸²**ï¼ä¸èƒ½æ˜¯åˆ—è¡¨ï¼
- å¹´ä»½ç”¨ _å¹´ä»½(æ•´æ•¸), å“åç”¨ str.contains() æœ '{name_col}'
- åœ“é¤…åœ–æœ€å¤š Top 8ï¼Œå…¶é¤˜åˆä½µã€Œå…¶ä»–ã€
- æ’åºï¼šå¹´æœˆ ascending=Trueï¼Œæ•¸é‡é‡‘é¡ ascending=False

## ç¯„æœ¬ï¼šä¸‰é¡ç”¢å“ä½”æ¯”ï¼ˆåœ“é¤…åœ–ï¼‰
```python
f2025 = df[df['_å¹´ä»½'] == 2025].copy()
foam = f2025[f2025['{name_col}'].str.contains('ç™¼æ³¡åˆ·', case=False, na=False)]
dib_cer = f2025[(f2025['{code_col}'].str.startswith('DIB', na=False)) & (f2025['{name_col}'].str.contains('é™¶ç“·åˆ·', case=False, na=False))]
other_cer = f2025[(~f2025['{code_col}'].str.startswith('DIB', na=False)) & (f2025['{name_col}'].str.contains('é™¶ç“·åˆ·', case=False, na=False))]
qty_col = '{qty_signed or "æ•¸é‡"}'
result_df = pd.DataFrame({{
    'å“å': ['ç™¼æ³¡åˆ·', 'DIBé™¶ç“·åˆ·', 'å…¶ä»–é™¶ç“·åˆ·'],
    'æ•¸é‡': [foam[qty_col].sum(), dib_cer[qty_col].sum(), other_cer[qty_col].sum()]
}})
chart_config = {{'x': 'å“å', 'y': 'æ•¸é‡', 'title': '2025å¹´ä¸‰å¤§ç”¢å“ç·šæ·¨éŠ·é‡ä½”æ¯”'}}
```

## ç¯„æœ¬ï¼šå¹³å‡å–®åƒ¹ (ASP)
```python
filtered = df[(df['_å¹´ä»½'] == 2025) & (df['{name_col}'].str.contains('ç™¼æ³¡åˆ·', case=False, na=False))].copy()
net_amt = filtered['{amt_signed or amt_untaxed or "æœªç¨…é‡‘é¡"}'].sum()
net_qty = filtered['{qty_signed or "æ•¸é‡"}'].sum()
asp = round(net_amt / net_qty, 2) if net_qty != 0 else 0
result_df = pd.DataFrame({{'æŒ‡æ¨™': ['æ·¨æ•¸é‡', 'æœªç¨…æ·¨é¡', 'å¹³å‡å–®åƒ¹(ASP)'], 'å€¼': [net_qty, net_amt, asp]}})
chart_config = {{'title': '2025å¹´ç™¼æ³¡åˆ·å¹³å‡å–®åƒ¹åˆ†æ'}}
```

## ç¯„æœ¬ï¼šæŸ¥ç„¡è³‡æ–™è™•ç†
```python
filtered = df[(df['{cust_col}'].str.contains('è¯é€š', case=False, na=False)) & (df['_å¹´ä»½'] == 2024) & (df['{code_col}'].str.startswith('DIB', na=False))].copy()
if len(filtered) == 0:
    result_df = pd.DataFrame({{'èªªæ˜': ['ğŸ” ç¶“æŸ¥è©¢ï¼Œè¯é€š 2024 å¹´ç„¡è³¼è²· DIB é™¶ç“·åˆ·ç´€éŒ„']}})
    chart_config = {{}}
else:
    result_df = filtered.groupby('_æœˆä»½')['{qty_signed or "æ•¸é‡"}'].sum().reset_index()
    result_df.columns = ['æœˆä»½', 'æ·¨æ•¸é‡']
    chart_config = {{'x': 'æœˆä»½', 'y': 'æ·¨æ•¸é‡', 'title': 'è¯é€š2024å¹´DIBé™¶ç“·åˆ·æœˆéŠ·é‡'}}
```

# æª¢æŸ¥æ¸…å–®
1. x,y,color æ˜¯å­—ä¸² 2. _å¹´ä»½æ•´æ•¸ 3. str.contains() æœ '{name_col}' 4. reset_index(drop=True)
5. ASP ç”¨æœªç¨…æ·¨é¡/æ·¨æ•¸é‡ 6. ç„¡éŠ·é€€æ¸›æ³• 7. åœ“é¤…Top8 8. ç¨‹å¼ç¢¼å®Œæ•´
9. âš ï¸ çµ•å°ä¸ç”¨ '{type_col}' æœç”¢å“å 10. æŸ¥ç„¡è³‡æ–™è¦å›å ± 11. å•åœ–è¡¨å¿…çµ¦ chart_config"""

    def analyze(self, query, df, meta, audit, history):
        msgs = [{"role": "system", "content": self._sysprompt(df, meta, audit, query)}]
        for h in history[-3:]:
            msgs.append({"role": "user", "content": h.get('query', '')})
            if h.get('code'):
                msgs.append({"role": "assistant", "content": json.dumps(
                    {"answer": h.get('answer',''), "code": h.get('code','')[:500]}, ensure_ascii=False)})
        msgs.append({"role": "user", "content": query})
        try:
            r = self.client.chat.completions.create(
                model=self.model, messages=msgs, temperature=TEMPERATURE,
                response_format={"type": "json_object"}, max_tokens=4000)
            result = json.loads(r.choices[0].message.content)
            if self._forbidden(result.get('code', '')): return self._fallback()

            # â­ åœ–è¡¨è§¸ç™¼æ©Ÿåˆ¶ï¼šå¼·åˆ¶ need_chart
            chart_kw = ['åœ–', 'chart', 'è¶¨å‹¢', 'ä½”æ¯”', 'åˆ†ä½ˆ', 'æ¯”ä¾‹', 'æ’å', 'top', 'pie', 'bar', 'line']
            if any(k in query.lower() for k in chart_kw):
                result['need_chart'] = True

            return result
        except Exception as e:
            return dict(answer=f"éŒ¯èª¤: {e}", thinking=traceback.format_exc(),
                        need_chart=False, chart_type="none", chart_color="", code="")

    def _forbidden(self, code):
        # ç²¾ç¢ºå®‰å…¨æª¢æŸ¥ï¼šåªæ“‹çœŸæ­£å±éšªçš„æ“ä½œï¼Œä¸èª¤æ®ºæ­£å¸¸ç¨‹å¼ç¢¼
        dangerous_imports = ['import os', 'import sys', 'import subprocess',
                             'import shutil', 'from os', 'from sys',
                             'from subprocess', 'from shutil']
        dangerous_calls = ['exec(', 'eval(', 'os.system', 'os.popen',
                           'subprocess.', 'shutil.rmtree', '__import__']
        dangerous_other = ['matplotlib', 'plt.show', 'plt.savefig']
        all_checks = dangerous_imports + dangerous_calls + dangerous_other
        return any(f in code for f in all_checks)

    def _fallback(self):
        return dict(answer="ç¨‹å¼ç¢¼ä¸å®‰å…¨ï¼Œè«‹é‡æ–°æè¿°ã€‚", thinking="å®‰å…¨æª¢æŸ¥å¤±æ•—",
                    need_chart=False, chart_type="none", chart_color="", code="")

    def execute_code(self, code, df):
        if not code or not code.strip(): return False, None, {}, "ç„¡ç¨‹å¼ç¢¼"
        if self._forbidden(code): return False, None, {}, "ç¦æ­¢å…§å®¹"
        g = {'pd': pd, 'np': np, 'df': df.copy(), 'result_df': None, 'chart_config': {}}
        try:
            exec(code, g)
            rdf = g.get('result_df')
            cc = self._fix_cc(g.get('chart_config', {}), rdf)
            if rdf is None:
                for k, v in g.items():
                    if isinstance(v, pd.DataFrame) and k != 'df' and len(v) > 0:
                        rdf = v; break
            if rdf is None: return False, None, {}, "ç„¡ result_df"
            if isinstance(rdf, pd.Series): rdf = rdf.reset_index()
            elif not isinstance(rdf, pd.DataFrame): rdf = pd.DataFrame({'çµæœ': [rdf]})
            # â­ å…è¨±ç©º result_dfï¼ˆæŸ¥ç„¡è³‡æ–™æƒ…å¢ƒï¼‰ï¼Œä¸å†å›å‚³å¤±æ•—
            return True, rdf, cc, ""
        except Exception as e:
            return False, None, {}, f"åŸ·è¡ŒéŒ¯èª¤: {e}\n{traceback.format_exc()}"

    def _fix_cc(self, cc, rdf):
        if not cc: return {}
        f = {}
        for k in ['x','y','color']:
            if k in cc:
                v = cc[k]
                f[k] = str(v[0]) if isinstance(v, list) and v else str(v) if v else ''
        for k in ['title','labels','text']:
            if k in cc: f[k] = cc[k]
        if rdf is not None and len(rdf.columns) >= 2:
            cols = list(rdf.columns)
            if 'x' not in f or not f.get('x'): f['x'] = str(cols[0])
            if 'y' not in f or not f.get('y'):
                for c in cols[1:]:
                    if pd.api.types.is_numeric_dtype(rdf[c]): f['y'] = str(c); break
                if 'y' not in f: f['y'] = str(cols[1])
        return f

    def fix_and_retry(self, code, error, query, df, meta, audit):
        nc = audit.get('product_name_cols', ['å°æ–¹å“å/å“åå‚™è¨»'])
        cc = audit.get('product_code_cols', ['ç”¢å“ä»£è™Ÿ'])
        tc = audit.get('type_cols', ['å–®åˆ¥åç¨±'])
        name_col = nc[0] if nc else 'å°æ–¹å“å/å“åå‚™è¨»'
        code_col = cc[0] if cc else 'ç”¢å“ä»£è™Ÿ'
        type_col = tc[0] if tc else 'å–®åˆ¥åç¨±'
        qty_s = audit.get('qty_signed_col', '')
        amt_s = audit.get('amount_signed_col', '')
        amt_u = audit.get('amount_untaxed_col', '')

        prompt = f"""ç¨‹å¼ç¢¼å¤±æ•—ï¼Œä¿®å¾©å®ƒã€‚
åŸå§‹: ```python\n{code}\n```
éŒ¯èª¤: {error}
å•é¡Œ: {query}

ä¿®å¾©è¦å‰‡:
1. chart_config x,y,color å­—ä¸²
2. å¹´ä»½ç”¨ _å¹´ä»½(æ•´æ•¸)
3. å“åæœ '{name_col}' + str.contains()
4. ä»£è™Ÿæœ '{code_col}'
5. âŒ ä¸ç”¨ '{type_col}' æœå“åï¼å®ƒåªæœ‰éŠ·è²¨/éŠ·é€€å€¼
6. æ·¨æ•¸é‡ç”¨ '{qty_s or "æ•¸é‡"}'ï¼ˆå·²å«æ­£è² è™Ÿæˆ–å¾Œç«¯å·²è½‰è² ï¼‰
7. æ·¨é‡‘é¡ç”¨ '{amt_s or amt_u or "æœªç¨…é‡‘é¡"}'
8. ASP = æœªç¨…æ·¨é¡/æ·¨æ•¸é‡ï¼Œç¦ç”¨å«ç¨…
9. result_df = DataFrame + reset_index(drop=True)
10. æŸ¥ç„¡è³‡æ–™å›å ±èªªæ˜æ–‡å­—

è¿”å›å®Œæ•´ JSONã€‚"""
        try:
            r = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role":"system","content":self._sysprompt(df,meta,audit,query)},
                          {"role":"user","content":prompt}],
                temperature=TEMPERATURE, response_format={"type":"json_object"}, max_tokens=4000)
            return json.loads(r.choices[0].message.content)
        except: return None


# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘  åœ–è¡¨ç”Ÿæˆå™¨ v16.1 â€” è·¨å¹´ä»½æ¯”è¼ƒè¦–è¦ºä¿®å¾©                          â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
class ChartGenerator:
    @staticmethod
    def create(data, chart_type, config, color_scheme=None):
        if data is None or len(data) == 0: return None
        x = safe_get_string(config.get('x'))
        y = safe_get_string(config.get('y'))
        color = safe_get_string(config.get('color'))
        title = safe_get_string(config.get('title'), 'æ•¸æ“šåˆ†æåœ–è¡¨')

        if not x or not y:
            cols = list(data.columns)
            if len(cols) >= 2:
                if not x: x = str(cols[0])
                if not y:
                    for c in cols[1:]:
                        if pd.api.types.is_numeric_dtype(data[c]): y = str(c); break
                    if not y and len(cols) > 1: y = str(cols[1])
        if not x or not y: return None
        if x not in data.columns or y not in data.columns: return None
        if color and color not in data.columns: color = ''

        data = data.copy()
        try:
            if not pd.api.types.is_numeric_dtype(data[y]):
                data[y] = pd.to_numeric(data[y], errors='coerce')
        except: pass
        
        # â­ v16.1 Visual Fix: å¹´ä»½å¿…é ˆè½‰å­—ä¸²é¿å… Plotly ç•«æˆæ¼¸å±¤è‰²
        try:
            if x in ['å¹´ä»½','_å¹´ä»½','year'] or 'å¹´' in str(x):
                if pd.api.types.is_numeric_dtype(data[x]):
                    data[x] = data[x].astype(int).astype(str)
            # é‡è¦ï¼šcolor æ¬„ä½è‹¥ç‚ºå¹´ä»½ï¼Œä¹Ÿå¿…é ˆè½‰å­—ä¸²ï¼
            if color and 'å¹´' in str(color) and pd.api.types.is_numeric_dtype(data[color]):
                data[color] = data[color].astype(int).astype(str)
        except: pass

        colors = COLOR_PALETTE.get(color_scheme, COLOR_PALETTE['default'])

        # åœ“é¤…åœ–è‡ªå‹•åˆä½µå°é …
        if chart_type in ('pie','donut') and len(data) > 10:
            data = ChartGenerator._merge_small(data, x, y, 8)

        try:
            fig = ChartGenerator._build(data, chart_type, x, y, color, title, colors)
            if fig: ChartGenerator._style(fig, title, len(data), chart_type)
            return fig
        except:
            try:
                fig = px.bar(data, x=x, y=y, title=title, color_discrete_sequence=colors)
                ChartGenerator._style(fig, title, len(data), 'bar')
                return fig
            except: return None

    @staticmethod
    def _merge_small(data, x, y, n=8):
        data = data.sort_values(y, ascending=False, key=abs).reset_index(drop=True)
        if len(data) <= n: return data
        top = data.head(n).copy()
        rest = pd.DataFrame({x: ['å…¶ä»–'], y: [data.iloc[n:][y].sum()]})
        return pd.concat([top, rest], ignore_index=True)

    @staticmethod
    def _build(data, ct, x, y, color, title, colors):
        kw = dict(title=title, color_discrete_sequence=colors)
        ckw = {}
        if color: ckw['color'] = color
        fig = None

        if ct == 'line':
            fig = px.line(data, x=x, y=y, markers=True, **kw, **ckw)
            fig.update_traces(line=dict(width=3), marker=dict(size=10))
        elif ct in ('area','stacked_area'):
            fig = px.area(data, x=x, y=y, **kw, **ckw)
        elif ct in ('stacked_bar','stacked'):
            fig = px.bar(data, x=x, y=y, barmode='stack', text=y, **kw, **ckw)
            fig.update_traces(texttemplate='%{text:,.0f}', textposition='inside', textfont=dict(size=11, color='white'))
        elif ct == 'grouped_bar':
            fig = px.bar(data, x=x, y=y, barmode='group', text=y, **kw, **ckw)
            fig.update_traces(texttemplate='%{text:,.0f}', textposition='outside', textfont=dict(size=11))
        elif ct == 'horizontal_bar':
            fig = px.bar(data, x=y, y=x, orientation='h', text=y, **kw, **ckw)
            fig.update_traces(texttemplate='%{text:,.0f}', textposition='outside', textfont=dict(size=11))
        elif ct == 'pie':
            fig = px.pie(data, names=x, values=y, title=title, color_discrete_sequence=colors)
            fig.update_traces(textposition='inside', textinfo='percent+label', textfont=dict(size=12))
        elif ct == 'donut':
            fig = px.pie(data, names=x, values=y, title=title, hole=0.45, color_discrete_sequence=colors)
            fig.update_traces(textposition='inside', textinfo='percent+label', textfont=dict(size=12))
        elif ct == 'scatter':
            fig = px.scatter(data, x=x, y=y, **kw, **ckw)
        elif ct == 'waterfall':
            try:
                fig = go.Figure(go.Waterfall(x=data[x].tolist(), y=data[y].tolist(),
                    connector={"line":{"color":"rgb(63,63,63)"}}))
                fig.update_layout(title=title)
            except: fig = px.bar(data, x=x, y=y, **kw)
        elif ct == 'funnel':
            try: fig = px.funnel(data, x=y, y=x, **kw)
            except: fig = px.bar(data, x=y, y=x, orientation='h', **kw)
        elif ct == 'radar':
            try:
                fig = go.Figure()
                fig.add_trace(go.Scatterpolar(r=data[y].tolist(), theta=data[x].tolist(),
                    fill='toself', name=y, line_color=colors[0]))
                fig.update_layout(polar=dict(radialaxis=dict(visible=True)), title=title)
            except: fig = px.bar(data, x=x, y=y, **kw)
        elif ct == 'heatmap':
            try:
                if color:
                    pv = data.pivot_table(values=y, index=x, columns=color, aggfunc='sum')
                    fig = px.imshow(pv, title=title, color_continuous_scale='RdYlBu_r')
                else: fig = px.bar(data, x=x, y=y, **kw)
            except: fig = px.bar(data, x=x, y=y, **kw)
        elif ct == 'treemap':
            try: fig = px.treemap(data, path=[x], values=y, **kw)
            except: fig = px.bar(data, x=x, y=y, **kw)
        elif ct == 'sunburst':
            try: fig = px.sunburst(data, path=[color, x] if color else [x], values=y, **kw)
            except: fig = px.pie(data, names=x, values=y, title=title, color_discrete_sequence=colors)
        else:  # default bar
            bkw = dict(text=y)
            if color: bkw['color'] = color; bkw['barmode'] = 'group'
            fig = px.bar(data, x=x, y=y, **kw, **bkw)
            fig.update_traces(texttemplate='%{text:,.0f}', textposition='outside', textfont=dict(size=12))
        return fig

    @staticmethod
    def _style(fig, title, n, ct='bar'):
        circ = ct in ('pie','donut','radar','treemap','sunburst')
        fig.update_layout(
            title=dict(text=title, font=dict(size=20, family='Microsoft JhengHei', color='#1a1a2e'),
                       x=0.5, xanchor='center', y=0.98, yanchor='top'),
            font=dict(size=13, family='Microsoft JhengHei', color='#2d3436'),
            height=580, hovermode='closest' if circ else 'x unified',
            plot_bgcolor='rgba(250,250,252,1)', paper_bgcolor='white',
            margin=dict(t=80, b=100, l=80, r=60),
        )
        if circ:
            fig.update_layout(
                legend=dict(orientation="h", yanchor="top", y=-0.12, xanchor="center", x=0.5,
                            font=dict(size=11), bgcolor='rgba(255,255,255,0.8)'),
                margin=dict(t=80, b=160, l=40, r=40),
            )
        else:
            fig.update_layout(
                legend=dict(orientation="h", yanchor="bottom", y=1.05, xanchor="center", x=0.5,
                            font=dict(size=12), bgcolor='rgba(255,255,255,0.8)'),
                yaxis=dict(tickformat=',', gridcolor='rgba(128,128,128,0.2)'),
                xaxis=dict(tickangle=-45 if n > 8 else 0, gridcolor='rgba(128,128,128,0.2)', type='category'),
            )
            # yè»¸ç•™ç™½è®“ text ä¸è¢«è£åˆ‡
            if ct in ('bar','grouped_bar'):
                try:
                    vals = [v for trace in fig.data for v in (trace.y if hasattr(trace,'y') and trace.y is not None else []) if v is not None]
                    if vals: fig.update_yaxes(range=[min(0, min(vals)*1.1), max(vals)*1.25])
                except: pass


# ============================================================================
# ğŸ–¥ï¸ Streamlit ä¸»ç¨‹å¼
# ============================================================================
def show_login_page():
    st.markdown(CUSTOM_CSS, unsafe_allow_html=True)
    st.markdown('<h1 class="main-header">ğŸ” ç³»çµ±ç™»å…¥</h1>', unsafe_allow_html=True)
    st.markdown('<p class="sub-header">ä¼æ¥­ç´š AI æ™ºèƒ½æ•¸æ“šåˆ†æå¹³å° v16.1</p>', unsafe_allow_html=True)
    c1, c2, c3 = st.columns([1, 2, 1])
    with c2:
        st.markdown("---")
        # ä½¿ç”¨ form è®“å¯†ç¢¼æ¬„ä½æ”¯æ´ Enter éµç™»å…¥
        with st.form(key="login_form", clear_on_submit=False):
            pwd = st.text_input("è«‹è¼¸å…¥å¯†ç¢¼", type="password", key="login_password")
            submitted = st.form_submit_button("ğŸš€ ç™»å…¥", type="primary", use_container_width=True)
            
            if submitted:
                if pwd == PASSWORD:
                    st.session_state.authenticated = True
                    st.rerun()
                else:
                    st.error("âŒ å¯†ç¢¼éŒ¯èª¤")


def show_main_app():
    st.markdown(CUSTOM_CSS, unsafe_allow_html=True)
    # åˆå§‹åŒ– session stateï¼ˆAPI key ä½¿ç”¨å…§å»ºå€¼ï¼‰
    defs = dict(df=None, metadata=None, history=[], ai_engine=None,
                debug_mode=False, cleaning_stats={}, cleaning_log=[], semantic_audit=None,
                available_sheets={}, selected_sheets={})
    for k, v in defs.items():
        if k not in st.session_state:
            st.session_state[k] = v

    # è‡ªå‹•åˆå§‹åŒ– AI å¼•æ“ï¼ˆä½¿ç”¨å…§å»º API Keyï¼‰
    if st.session_state.ai_engine is None:
        st.session_state.ai_engine = LogicalBrainEngine(EMBEDDED_API_KEY)

    st.markdown('<h1 class="main-header">ğŸ¤– AI æ™ºèƒ½æ•¸æ“šåˆ†æå¸«</h1>', unsafe_allow_html=True)

    # â”€â”€ å´é‚Šæ¬„ï¼ˆå·²ç§»é™¤ API Key è¼¸å…¥ï¼‰â”€â”€
    with st.sidebar:
        st.header("âš™ï¸ ç³»çµ±è¨­å®š")
        st.session_state.debug_mode = st.checkbox("ğŸ› é™¤éŒ¯æ¨¡å¼", value=st.session_state.debug_mode)

        st.divider()
        st.header("ğŸ“ ä¸Šå‚³è³‡æ–™")
        files = st.file_uploader("é¸æ“‡ Excel æª”æ¡ˆ", type=['xlsx','xls'], accept_multiple_files=True)

        # â”€â”€ å·¥ä½œè¡¨é¸æ“‡å™¨ï¼ˆä¿®å¾©ç‰ˆï¼‰â”€â”€
        if files:
            st.markdown("### ğŸ“‹ å·¥ä½œè¡¨é¸æ“‡")
            temp_avail = {}
            for f in files:
                try:
                    fb = f.read(); f.seek(0)
                    xls = pd.ExcelFile(io.BytesIO(fb))
                    valid = [s for s in xls.sheet_names if not any(k in s.lower() for k in DataCleaningEngine.SKIP_SHEET_KW)]
                    temp_avail[f.name] = valid if valid else xls.sheet_names
                except: continue
            st.session_state.available_sheets = temp_avail

            if temp_avail:
                show_sel = st.checkbox("ğŸ” æ‰‹å‹•é¸æ“‡å·¥ä½œè¡¨", value=False,
                    help="é è¨­è¼‰å…¥æ‰€æœ‰å·¥ä½œè¡¨ï¼ˆæ™ºæ…§è·¯ç”±æœƒè‡ªå‹•ä¸Ÿæ£„ç¸½è¡¨ï¼‰")

                if show_sel:
                    for fname, sheets in temp_avail.items():
                        st.markdown(f"**ğŸ“„ {fname}**")
                        # ç”¨ç¨ç«‹ session_state key ç®¡ç†æ¯å€‹æª”æ¡ˆçš„é¸æ“‡
                        sk = f"_sheetsel_{fname}"
                        if sk not in st.session_state:
                            st.session_state[sk] = sheets.copy()

                        selected = st.multiselect("é¸æ“‡å·¥ä½œè¡¨", options=sheets,
                            default=st.session_state[sk], key=f"ms_{fname}", label_visibility="collapsed")
                        st.session_state[sk] = selected
                        st.session_state.selected_sheets[fname] = selected
                        st.caption(f"å·²é¸ {len(selected)}/{len(sheets)}")
                        st.markdown("---")
                else:
                    st.session_state.selected_sheets = {}
                    total = sum(len(s) for s in temp_avail.values())
                    st.info(f"ğŸ’¡ é è¨­å…¨éƒ¨è¼‰å…¥ ({total} å€‹å·¥ä½œè¡¨)ï¼Œæ™ºæ…§è·¯ç”±è‡ªå‹•è™•ç†ç¸½è¡¨")

        # è¼‰å…¥æŒ‰éˆ•
        if files:
            if st.button("ğŸš€ è¼‰å…¥ä¸¦æ¸…æ´—è³‡æ–™", type="primary", use_container_width=True, key="sidebar_load_data"):
                with st.spinner("ğŸ”„ ä¸‰å¤§å¼•æ“å•Ÿå‹•ä¸­..."):
                    try:
                        sel = st.session_state.selected_sheets if st.session_state.selected_sheets else None
                        cleaner = DataCleaningEngine()
                        df, meta, stats = cleaner.clean(files, sel)
                        if df is not None and len(df) > 0:
                            st.session_state.df = df
                            st.session_state.metadata = meta
                            st.session_state.cleaning_stats = stats
                            st.session_state.cleaning_log = cleaner.log
                            st.session_state.history = []
                            detector = SemanticDetectionModule()
                            st.session_state.semantic_audit = detector.audit(df, meta)
                            st.success(f"âœ… è¼‰å…¥ {len(df):,} ç­†ï¼ˆéŠ·é€€å·²è½‰è² ï¼Œç¸½è¡¨å·²éæ¿¾ï¼‰")
                        else:
                            st.error("âŒ ç„¡æœ‰æ•ˆè³‡æ–™")
                    except Exception as e:
                        st.error(f"âŒ è¼‰å…¥å¤±æ•—: {e}")

        # å¼•æ“ç‹€æ…‹
        if st.session_state.df is not None:
            stats = st.session_state.cleaning_stats
            st.divider()
            st.markdown("### ğŸ—ï¸ å¼•æ“ç‹€æ…‹")
            st.markdown(f"""<div class="engine-report">
<b>ğŸ§¹ æ•¸æ“šæ¸…æ´—å¼•æ“</b><br>
æª”æ¡ˆ: {stats.get('total_files',0)} | å·¥ä½œè¡¨: {stats.get('total_sheets_read',0)} |
ä¸Ÿæ£„ç¸½è¡¨: {stats.get('sheets_skipped_summary',0)}<br>
å»é‡: {stats.get('dedup_strategy','-')} | ç§»é™¤: {stats.get('duplicates_removed',0):,}<br>
<b>ğŸ”„ éŠ·é€€è½‰è² : {stats.get('return_rows_negated',0):,} ç­†</b> (æ¬„ä½: {stats.get('return_type_col','-')})<br>
æ•¸å€¼: {stats.get('numeric_cols_standardized',0)} æ¬„ | æ—¥æœŸ: {stats.get('date_cols_processed',0)} æ¬„
</div>""", unsafe_allow_html=True)

            audit = st.session_state.semantic_audit
            if audit:
                st.markdown(f"""<div class="engine-report">
<b>ğŸ¯ èªæ„æ„ŸçŸ¥</b><br>{audit.get('summary_text','').replace(chr(10), '<br>')}
</div>""", unsafe_allow_html=True)

            with st.expander("ğŸ“‹ æ¸…æ´—æ—¥èªŒ", expanded=False):
                for l in st.session_state.cleaning_log:
                    st.markdown(f"- {l}")

            st.divider()
            c1, c2 = st.columns(2)
            with c1:
                if st.button("ğŸ—‘ï¸ æ¸…é™¤è³‡æ–™", key="sidebar_clear_data"):
                    for k in ['df','metadata','history','cleaning_stats','cleaning_log','semantic_audit']:
                        st.session_state[k] = defs.get(k)
                    st.rerun()
            with c2:
                if st.button("ğŸ”„ æ¸…é™¤å°è©±", key="sidebar_clear_history"):
                    st.session_state.history = []
                    st.rerun()

            with st.expander("ğŸ‘€ è³‡æ–™é è¦½"):
                pcols = [c for c in st.session_state.df.columns if not str(c).startswith('_')]
                st.dataframe(st.session_state.df[pcols].head(10), use_container_width=True)

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ä¸»ç•«é¢
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    if st.session_state.df is None:
        st.info("ğŸ‘ˆ è«‹å…ˆåœ¨å·¦å´ä¸Šå‚³ Excel æª”æ¡ˆ")
        return

    df = st.session_state.df
    meta = st.session_state.metadata
    audit = st.session_state.semantic_audit or {}
    ai = st.session_state.ai_engine
    debug = st.session_state.debug_mode

    # é¡¯ç¤ºæ­·å²
    for i, item in enumerate(st.session_state.history):
        with st.chat_message("user"):
            st.write(item.get('query', ''))
        with st.chat_message("assistant"):
            if item.get('answer'): st.markdown(item['answer'])
            if item.get('thinking'):
                with st.expander("ğŸ§  åˆ†ææ€è·¯", expanded=False):
                    st.markdown(f'<div class="thinking-box">{item["thinking"]}</div>', unsafe_allow_html=True)
            rdf = item.get('result_df')
            if item.get('need_chart') and rdf is not None and len(rdf) > 0:
                try:
                    fig = ChartGenerator.create(rdf, item.get('chart_type','bar'),
                        item.get('chart_config',{}), item.get('chart_color',''))
                    if fig: st.plotly_chart(fig, use_container_width=True, key=f"h_{i}_{hash(str(item.get('query','')))}")
                except: pass
            if rdf is not None and len(rdf) > 0:
                st.markdown(f'<div class="data-header">ğŸ“‹ æŸ¥è©¢çµæœ ({len(rdf):,} ç­†)</div>', unsafe_allow_html=True)
                ddf = rdf.copy(); ddf.index = range(1, len(ddf)+1)
                for col in ddf.columns:
                    try:
                        if pd.api.types.is_numeric_dtype(ddf[col]): ddf[col] = ddf[col].apply(format_number)
                    except: pass
                st.dataframe(ddf, use_container_width=True, height=min(400, len(ddf)*35+50))
            if debug and item.get('code'):
                with st.expander("ğŸ’» ç¨‹å¼ç¢¼"): st.code(item['code'], language='python')

    # è¼¸å…¥
    query = st.chat_input("è«‹è¼¸å…¥å•é¡Œ...")
    if query:
        with st.chat_message("user"):
            st.write(query)
        with st.chat_message("assistant"):
            with st.spinner("ğŸ§  AI åˆ†æä¸­..."):
                ai_result = ai.analyze(query, df, meta, audit, st.session_state.history)
                answer = ai_result.get('answer', '')
                thinking = ai_result.get('thinking', '')
                need_chart = ai_result.get('need_chart', False)
                chart_type = ai_result.get('chart_type', 'bar')
                chart_color = ai_result.get('chart_color', '')
                code = ai_result.get('code', '')
                result_df = None
                chart_config = {}

                if code:
                    success, result_df, chart_config, error = ai.execute_code(code, df)
                    if not success:
                        for retry in range(MAX_RETRIES):
                            if debug: st.warning(f"âš ï¸ ç¬¬ {retry+1} æ¬¡ä¿®å¾©...")
                            fixed = ai.fix_and_retry(code, error, query, df, meta, audit)
                            if fixed and fixed.get('code'):
                                success, result_df, chart_config, nerr = ai.execute_code(fixed['code'], df)
                                if success:
                                    code = fixed['code']
                                    answer = fixed.get('answer', answer)
                                    thinking = fixed.get('thinking', thinking)
                                    if debug: st.success("âœ… ä¿®å¾©æˆåŠŸ!")
                                    break
                                error = nerr
                        if not success and debug: st.error(f"âŒ å¤±æ•—: {error}")

                st.session_state.history.append(dict(
                    query=query, answer=answer, thinking=thinking,
                    need_chart=need_chart, chart_type=chart_type, chart_color=chart_color,
                    code=code, result_df=result_df, chart_config=chart_config))

            if answer: st.markdown(answer)
            if thinking:
                with st.expander("ğŸ§  åˆ†ææ€è·¯", expanded=False):
                    st.markdown(f'<div class="thinking-box">{thinking}</div>', unsafe_allow_html=True)
            if need_chart and result_df is not None and len(result_df) > 0:
                try:
                    fig = ChartGenerator.create(result_df, chart_type, chart_config, chart_color)
                    if fig: st.plotly_chart(fig, use_container_width=True)
                except Exception as e:
                    if debug: st.error(f"åœ–è¡¨éŒ¯èª¤: {e}")
            if result_df is not None and len(result_df) > 0:
                st.markdown(f'<div class="data-header">ğŸ“‹ æŸ¥è©¢çµæœ ({len(result_df):,} ç­†)</div>', unsafe_allow_html=True)
                ddf = result_df.copy(); ddf.index = range(1, len(ddf)+1)
                for col in ddf.columns:
                    try:
                        if pd.api.types.is_numeric_dtype(ddf[col]): ddf[col] = ddf[col].apply(format_number)
                    except: pass
                st.dataframe(ddf, use_container_width=True, height=min(450, len(ddf)*35+50))
            elif code and (result_df is None or len(result_df) == 0):
                st.warning("âš ï¸ æŸ¥è©¢æ²’æœ‰çµæœï¼Œè«‹æª¢æŸ¥æ¢ä»¶")
            if debug and code:
                with st.expander("ğŸ’» ç¨‹å¼ç¢¼"): st.code(code, language='python')
                if chart_config:
                    with st.expander("ğŸ“Š chart_config"): st.json(chart_config)


def main():
    st.set_page_config(page_title=PAGE_TITLE, page_icon=PAGE_ICON, layout="wide", initial_sidebar_state="expanded")
    if 'authenticated' not in st.session_state:
        st.session_state.authenticated = False
    if not st.session_state.authenticated:
        show_login_page()
    else:
        show_main_app()

if __name__ == "__main__":
    main()