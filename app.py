# app.py
# -*- coding: utf-8 -*-
"""
ChatGPT-like BI Assistant (API Key login)
- Sidebar: upload Excel, show tables, clear chat
- Main: chat UI (st.chat_message + st.chat_input)
- Multi-file, multi-sheet ingestion
- Chinese-first semantic understanding
- Robustness: JSON extraction + retry + auto-fix code + fallback outputs
- Sandboxed execution with whitelist import (pandas/numpy/plotly)
"""

from __future__ import annotations

import io
import os
import re
import json
import sys
import time
import pickle
import tempfile
import subprocess
from dataclasses import dataclass
from typing import Dict, List, Any, Optional, Tuple

import numpy as np
import pandas as pd
import streamlit as st

from openai import OpenAI
from openai import RateLimitError, APIError, APITimeoutError


# -----------------------------
# Config
# -----------------------------
st.set_page_config(page_title="AI è³‡æ–™åˆ†æåŠ©ç†", layout="wide")

APP_TITLE = "AI è³‡æ–™åˆ†æåŠ©ç†"
DEFAULT_MODEL = "gpt-4.1-mini"     # ä½ æ—¥å¾Œæƒ³æ›æ›´å¼·æ¨¡å‹å†æ”¹é€™è£¡
TOPK_TABLES = 6                    # å›ºå®šï¼šä¸çµ¦ä½ èª¿ï¼Œç³»çµ±è‡ªå‹•å„ªåŒ–
SANDBOX_TIMEOUT = 18               # å›ºå®šï¼šä¸çµ¦ä½ èª¿
HEAD_ROWS = 12
HEAD_COLS = 40


# -----------------------------
# API Key Login (per-session)
# -----------------------------
def require_api_key() -> str:
    if "openai_api_key" not in st.session_state:
        st.session_state.openai_api_key = ""

    st.title(APP_TITLE)
    st.caption("è«‹è¼¸å…¥ä½ çš„ OpenAI API Keyã€‚Key åªå­˜åœ¨æ­¤ç€è¦½å™¨ Sessionï¼Œé—œé–‰é é¢å°±æ¶ˆå¤±ã€‚")

    api_key = st.text_input("OpenAI API Key", type="password", placeholder="sk-xxxxxxxxxxxxxxxxxxxxxxxx")
    if st.button("âœ… é–‹å§‹ä½¿ç”¨", use_container_width=True):
        if not api_key or not api_key.startswith("sk-"):
            st.error("API Key æ ¼å¼ä¸æ­£ç¢ºï¼ˆé€šå¸¸ä»¥ sk- é–‹é ­ï¼‰ã€‚")
            st.stop()
        try:
            client = OpenAI(api_key=api_key)
            _ = client.models.list()
        except RateLimitError:
            st.error("API Key å¯ç”¨ï¼Œä½†ç›®å‰é¡åº¦ä¸è¶³/æœªé–‹é€š Billingï¼ˆ429ï¼‰ã€‚è«‹å…ˆå„²å€¼å¾Œå†è©¦ã€‚")
            st.stop()
        except Exception:
            st.error("API Key é©—è­‰å¤±æ•—ï¼šè«‹ç¢ºèª Key æœ‰æ•ˆã€å·²å•Ÿç”¨ Billing ä¸”æœ‰å¯ç”¨é¡åº¦ã€‚")
            st.stop()

        st.session_state.openai_api_key = api_key
        st.rerun()

    if not st.session_state.openai_api_key:
        st.stop()

    return st.session_state.openai_api_key


# -----------------------------
# Data ingestion
# -----------------------------
@dataclass
class TableProfile:
    key: str
    rows: int
    cols: int
    columns: List[str]
    dtypes: Dict[str, str]
    sample_head: List[Dict[str, Any]]


def read_excel_all_sheets(uploaded_file) -> Dict[str, pd.DataFrame]:
    data = uploaded_file.read()
    bio = io.BytesIO(data)
    xls = pd.ExcelFile(bio)
    out: Dict[str, pd.DataFrame] = {}
    for sheet in xls.sheet_names:
        df = pd.read_excel(bio, sheet_name=sheet)
        bio.seek(0)
        out[f"{uploaded_file.name} | {sheet}"] = df
    return out


def try_parse_datetime(df: pd.DataFrame) -> pd.DataFrame:
    df2 = df.copy()
    for c in df2.columns:
        name = str(c)
        if any(k in name for k in ["æ—¥æœŸ", "æ™‚é–“", "date", "time", "å¹´æœˆ", "æœˆä»½"]):
            try:
                df2[c] = pd.to_datetime(df2[c], errors="coerce")
            except Exception:
                pass
    return df2


def build_profile(key: str, df: pd.DataFrame) -> TableProfile:
    head = df.head(HEAD_ROWS)
    if head.shape[1] > HEAD_COLS:
        head = head.iloc[:, :HEAD_COLS]
    return TableProfile(
        key=key,
        rows=int(df.shape[0]),
        cols=int(df.shape[1]),
        columns=[str(c) for c in df.columns.tolist()],
        dtypes={str(c): str(df[c].dtype) for c in df.columns},
        sample_head=head.fillna("").astype(str).to_dict(orient="records"),
    )


# -----------------------------
# Retrieval (Chinese-friendly, no deps)
# -----------------------------
def normalize(s: str) -> str:
    s = str(s or "").strip().lower()
    s = re.sub(r"\s+", " ", s)
    return s


def ngrams(s: str, n: int) -> List[str]:
    s = normalize(s)
    s = re.sub(r"[^\w\u4e00-\u9fff]+", "", s)
    if len(s) <= n:
        return [s] if s else []
    return [s[i:i+n] for i in range(len(s) - n + 1)]


def score_table(question: str, p: TableProfile) -> float:
    qg = set(ngrams(question, 2) + ngrams(question, 3))
    if not qg:
        return 0.0
    meta = " ".join([p.key] + p.columns + list(p.dtypes.keys()))
    mg = set(ngrams(meta, 2) + ngrams(meta, 3))
    if not mg:
        return 0.0

    inter = len(qg & mg)
    union = len(qg | mg)
    jacc = inter / union if union else 0.0

    boost = 0.0
    q = question
    kl = p.key.lower()
    if any(k in q for k in ["æ¡è³¼", "é€²è²¨", "ä¾›æ‡‰å•†"]) and any(k in kl for k in ["purchase", "æ¡è³¼", "é€²è²¨"]):
        boost += 0.10
    if any(k in q for k in ["éŠ·å”®", "éŠ·è²¨", "ç‡Ÿæ”¶"]) and any(k in kl for k in ["sales", "éŠ·å”®", "éŠ·è²¨"]):
        boost += 0.10
    return float(jacc + boost)


def pick_tables(question: str, profiles: Dict[str, TableProfile], topk: int) -> List[str]:
    scored = [(score_table(question, p), k) for k, p in profiles.items()]
    scored.sort(key=lambda x: x[0], reverse=True)
    keys = [k for s, k in scored[:topk] if s > 0]
    if not keys and scored:
        keys = [scored[0][1]]
    return keys


def tables_context_json(keys: List[str], profiles: Dict[str, TableProfile]) -> str:
    blocks = []
    for k in keys:
        p = profiles[k]
        blocks.append({
            "table_key": p.key,
            "rows": p.rows,
            "cols": p.cols,
            "columns": p.columns,
            "dtypes": p.dtypes,
            "sample_head": p.sample_head,
        })
    return json.dumps(blocks, ensure_ascii=False, indent=2)


# -----------------------------
# LLM prompting (robust JSON output)
# -----------------------------
SYSTEM_PROMPT = """ä½ æ˜¯ä¸€å€‹ä¼æ¥­ç´šè³‡æ–™åˆ†æåŠ©ç†ï¼Œæ“…é•·ç”¨ pandas/numpy/plotly åšè³‡æ–™åˆ†æèˆ‡åœ–è¡¨ã€‚
ä½¿ç”¨è€…ç”¨ç¹é«”ä¸­æ–‡å£èªæå•ï¼Œä½ å¿…é ˆç”¨èªæ„ç†è§£æ±ºå®šè¦ç”¨å“ªäº›è¡¨ã€å“ªäº›æ¬„ä½ã€æ€éº¼åˆ†ç¾¤ã€æ€éº¼è¨ˆç®—ã€‚

ä½ æœƒå–å¾— dfs: Dict[str, pandas.DataFrame]ï¼Œkey ç‚º table_keyï¼ˆä¾‹å¦‚ "sales_2023_2025.xlsx | 2023ç¸½è¡¨"ï¼‰ã€‚

ä½ å¿…é ˆç”¢ç”Ÿã€Œå¯åŸ·è¡Œ Python ç¨‹å¼ç¢¼ã€ä¾†å®Œæˆåˆ†æï¼Œä¸¦ä¸”ç¨‹å¼ç¢¼ä¸€å®šè¦è¨­å®šï¼š
- final_answer: strï¼ˆç¹é«”ä¸­æ–‡çµè«–ï¼‰
- result_tables: Dict[str, pandas.DataFrame]ï¼ˆè‡³å°‘æ”¾ 1 å¼µè¡¨ï¼‰
- result_plotly_json: Optional[str]ï¼ˆè‹¥æœ‰åœ–ï¼Œç”¨ fig.to_json()ï¼›æ²’æœ‰å‰‡ Noneï¼‰

è¦å‰‡ï¼š
1) æ—¥æœŸæ¬„ä½è«‹ç”¨ pd.to_datetime(errors="coerce")ï¼›æ¯æœˆå½™ç¸½è¦ç”¢ç”Ÿã€ŒYYYY-MMã€å­—ä¸²æ¬„ä½ï¼ˆä¾‹å¦‚æ¬„åå« 'å¹´æœˆ'ï¼‰ã€‚
2) å°å­é›†è³¦å€¼å‰å…ˆ .copy()ï¼Œä¸¦ç”¨ .locã€‚
3) åŒæ™‚ç•«ã€Œæ•¸é‡ã€èˆ‡ã€Œé‡‘é¡ã€æ™‚å¿…é ˆé›™ y è»¸ï¼ˆæ•¸é‡å·¦è»¸ã€é‡‘é¡å³è»¸ï¼‰ï¼Œé¿å…æ•¸é‡çœ‹èµ·ä¾†åƒ 0ã€‚
4) æ¬„ä½åç›¡é‡ä¿ç•™ä¸­æ–‡ï¼Œä¸è¦ç„¡æ•…æ”¹æˆ Month é€™ç¨®è‹±æ–‡ã€‚
é™åˆ¶ï¼šåªèƒ½ import pandas, numpy, plotlyï¼ˆgraph_objects/expressï¼‰ã€‚ç¦æ­¢ç¶²è·¯ã€æª”æ¡ˆ IOã€ç³»çµ±æŒ‡ä»¤ã€å…¶å®ƒç¬¬ä¸‰æ–¹å¥—ä»¶ã€‚

è¼¸å‡ºæ ¼å¼ï¼ˆéå¸¸é‡è¦ï¼‰ï¼š
è«‹åªè¼¸å‡º JSONï¼ˆä¸è¦ markdownï¼‰ï¼Œæ ¼å¼ï¼š
{
  "python_code": "<ä½ çš„Pythonç¨‹å¼ç¢¼å­—ä¸²>"
}
"""


def extract_json_object(text: str) -> Optional[dict]:
    """Try to parse JSON from model output even if extra text exists."""
    text = (text or "").strip()
    if not text:
        return None
    # direct
    try:
        obj = json.loads(text)
        if isinstance(obj, dict):
            return obj
    except Exception:
        pass

    # find first {...} block
    m = re.search(r"\{[\s\S]*\}", text)
    if not m:
        return None
    chunk = m.group(0)
    try:
        obj = json.loads(chunk)
        if isinstance(obj, dict):
            return obj
    except Exception:
        return None
    return None


def extract_text(resp) -> str:
    parts = []
    for o in getattr(resp, "output", []) or []:
        if getattr(o, "type", None) == "message":
            for c in getattr(o, "content", []) or []:
                if getattr(c, "type", None) == "output_text":
                    parts.append(getattr(c, "text", "") or "")
    return "\n".join(parts).strip()


def llm_get_code_json(client: OpenAI, model: str, question: str, tables_json: str, extra_feedback: str = "") -> str:
    user_prompt = f"""ä½¿ç”¨è€…å•é¡Œï¼š
{question}

å¯ç”¨è³‡æ–™è¡¨è³‡è¨Šï¼ˆJSONï¼‰ï¼š
{tables_json}

{extra_feedback}
è«‹ä¾ç…§ç³»çµ±è¦æ±‚è¼¸å‡º JSONï¼Œä¸¦åœ¨ python_code å…§æä¾›å®Œæ•´å¯åŸ·è¡Œç¨‹å¼ç¢¼ã€‚
"""
    resp = client.responses.create(
        model=model,
        input=[
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": user_prompt},
        ],
    )
    return extract_text(resp)


def get_python_code_with_retries(client: OpenAI, model: str, question: str, tables_json: str) -> Tuple[str, List[str]]:
    """Return python_code and debug logs."""
    logs: List[str] = []
    feedback = ""
    for attempt in range(1, 4):
        raw = llm_get_code_json(client, model, question, tables_json, extra_feedback=feedback)
        obj = extract_json_object(raw)
        if obj and isinstance(obj.get("python_code"), str) and obj["python_code"].strip():
            code = obj["python_code"].strip()
            # quick sanity: required variables
            if "final_answer" in code and "result_tables" in code and "result_plotly_json" in code:
                logs.append(f"Attempt {attempt}: OK")
                return code, logs
            else:
                logs.append(f"Attempt {attempt}: Missing required vars, retry")
                feedback = "âš ï¸ ä½ ä¸Šä¸€è¼ªçš„ python_code æ²’æœ‰æ­£ç¢ºè¨­å®š final_answer / result_tables / result_plotly_jsonï¼Œè«‹ä¿®æ­£ä¸¦é‡æ–°è¼¸å‡º JSONã€‚"
                continue

        logs.append(f"Attempt {attempt}: JSON parse failed / empty, retry")
        feedback = "âš ï¸ ä½ ä¸Šä¸€è¼ªæ²’æœ‰è¼¸å‡ºæ­£ç¢º JSONï¼ˆæˆ– python_code ç‚ºç©ºï¼‰ã€‚è«‹åªè¼¸å‡º JSONï¼Œä¸” python_code å¿…é ˆæ˜¯å®Œæ•´ç¨‹å¼ç¢¼ã€‚"

    # last resort: return empty code (caller will fallback)
    return "", logs


# -----------------------------
# Sandbox execution (subprocess)
# - NO template injection -> no SyntaxError
# - Whitelist import roots: pandas/numpy/plotly
# - Convert datetime columns to ISO strings in returned tables
# -----------------------------
RUNNER = r"""
import json, pickle, traceback, warnings
import pandas as pd
import numpy as np

warnings.filterwarnings("ignore")

def safe_import(name, globals=None, locals=None, fromlist=(), level=0):
    root = name.split(".")[0]
    if root not in {"pandas", "numpy", "plotly"}:
        raise ImportError(f"Import of '{name}' is not allowed")
    return __import__(name, globals, locals, fromlist, level)

SAFE_BUILTINS = {
    "__import__": safe_import,
    "len": len, "range": range, "min": min, "max": max, "sum": sum,
    "abs": abs, "round": round, "sorted": sorted, "enumerate": enumerate,
    "zip": zip, "list": list, "dict": dict, "set": set, "tuple": tuple,
    "float": float, "int": int, "str": str, "bool": bool, "print": print,
}

with open("dfs.pkl", "rb") as f:
    dfs = pickle.load(f)

with open("user_code.py", "r", encoding="utf-8") as f:
    code = f.read()

local_env = {
    "pd": pd,
    "np": np,
    "dfs": dfs,
    "final_answer": "",
    "result_tables": {},
    "result_plotly_json": None,
}

result = {"ok": True, "final_answer": "", "tables": {}, "plotly_json": None, "stderr": ""}

def df_to_records_json(df: pd.DataFrame) -> str:
    out = df.copy()
    for col in out.columns:
        if pd.api.types.is_datetime64_any_dtype(out[col]):
            out[col] = out[col].dt.strftime("%Y-%m-%d %H:%M:%S")
    return out.to_json(orient="records", force_ascii=False)

try:
    exec(compile(code, "<user_code>", "exec"), {"__builtins__": SAFE_BUILTINS}, local_env)

    final_answer = str(local_env.get("final_answer", "") or "")
    result_tables = local_env.get("result_tables", {}) or {}
    plotly_json = local_env.get("result_plotly_json", None)

    tables_out = {}
    for name, df in result_tables.items():
        if isinstance(df, pd.DataFrame):
            df2 = df.copy()
            if len(df2) > 2000:
                df2 = df2.head(2000)
            tables_out[str(name)] = df_to_records_json(df2)

    result["final_answer"] = final_answer
    result["tables"] = tables_out
    result["plotly_json"] = plotly_json if isinstance(plotly_json, str) else None

except Exception:
    result["ok"] = False
    result["stderr"] = traceback.format_exc()

with open("out.json", "w", encoding="utf-8") as f:
    json.dump(result, f, ensure_ascii=False)
"""


def run_sandbox(user_code: str, dfs: Dict[str, pd.DataFrame], timeout_sec: int) -> Dict[str, Any]:
    with tempfile.TemporaryDirectory() as td:
        with open(os.path.join(td, "dfs.pkl"), "wb") as f:
            pickle.dump(dfs, f)
        with open(os.path.join(td, "user_code.py"), "w", encoding="utf-8") as f:
            f.write(user_code)
        with open(os.path.join(td, "runner.py"), "w", encoding="utf-8") as f:
            f.write(RUNNER)

        try:
            proc = subprocess.run(
                [sys.executable, "runner.py"],
                cwd=td,
                capture_output=True,
                text=True,
                timeout=timeout_sec,
            )
        except subprocess.TimeoutExpired:
            return {"ok": False, "stderr": f"Execution timeout after {timeout_sec}s.", "final_answer": "", "tables": {}, "plotly_json": None}

        out_path = os.path.join(td, "out.json")
        if not os.path.exists(out_path):
            return {"ok": False, "stderr": "Sandbox did not produce out.json.", "final_answer": "", "tables": {}, "plotly_json": None}

        with open(out_path, "r", encoding="utf-8") as f:
            res = json.load(f)
        res["_runner_stderr"] = proc.stderr
        return res


# -----------------------------
# Fallback (never empty)
# -----------------------------
def fallback_answer(dfs: Dict[str, pd.DataFrame], selected_keys: List[str]) -> Tuple[str, Dict[str, pd.DataFrame], Optional[str]]:
    lines = ["æ¨¡å‹æœ¬æ¬¡æ²’æœ‰ç”¢å‡ºå¯ç”¨åˆ†æç¨‹å¼ç¢¼ï¼Œæˆ‘å…ˆçµ¦ä½ ä¿åº•è³‡è¨Šï¼ˆç¢ºä¿æ°¸é ä¸æœƒç©ºç™½ï¼‰ï¼š", ""]
    tables: Dict[str, pd.DataFrame] = {}
    for k in selected_keys[:3]:
        df = dfs[k]
        lines.append(f"- ä½¿ç”¨è¡¨ï¼š{k}ï¼ˆ{df.shape[0]} rows Ã— {df.shape[1]} colsï¼‰")
        lines.append(f"  æ¬„ä½ï¼š{', '.join([str(c) for c in df.columns[:30]])}{'...' if df.shape[1] > 30 else ''}")
        tables[f"HEADï½œ{k}"] = df.head(20)
    return "\n".join(lines), tables, None


# -----------------------------
# App start
# -----------------------------
api_key = require_api_key()
client = OpenAI(api_key=api_key)

# Session init
if "dfs" not in st.session_state:
    st.session_state.dfs = {}
if "profiles" not in st.session_state:
    st.session_state.profiles = {}
if "messages" not in st.session_state:
    st.session_state.messages = []  # [{"role":"user"/"assistant", "content":..., "tables":..., "plotly_json":...}]

# -----------------------------
# Sidebar (GPT-like)
# -----------------------------
with st.sidebar:
    st.header("ğŸ“ è³‡æ–™")
    uploads = st.file_uploader("ä¸Šå‚³ Excelï¼ˆå¯å¤šé¸ï¼‰", type=["xlsx"], accept_multiple_files=True)

    if uploads:
        dfs: Dict[str, pd.DataFrame] = {}
        profiles: Dict[str, TableProfile] = {}
        for uf in uploads:
            try:
                temp = read_excel_all_sheets(uf)
            except Exception as e:
                st.error(f"è®€å– {uf.name} å¤±æ•—ï¼š{e}")
                continue
            for k, df in temp.items():
                df2 = try_parse_datetime(df)
                dfs[k] = df2
                profiles[k] = build_profile(k, df2)

        st.session_state.dfs = dfs
        st.session_state.profiles = profiles

    if st.session_state.dfs:
        st.success(f"å·²è¼‰å…¥ {len(st.session_state.dfs)} å¼µè¡¨")
        with st.expander("æŸ¥çœ‹è¡¨æ¸…å–®", expanded=False):
            for k, p in st.session_state.profiles.items():
                st.write(f"- {k}ï¼ˆ{p.rows}Ã—{p.cols}ï¼‰")
    else:
        st.info("å…ˆä¸Šå‚³ Excel æ‰èƒ½åˆ†æ")

    st.divider()
    if st.button("ğŸ§¹ æ¸…é™¤å°è©±", use_container_width=True):
        st.session_state.messages = []
        st.rerun()

    st.caption("æç¤ºï¼šæ­¤ä»‹é¢åƒ GPTï¼šå·¦é‚Šç®¡è³‡æ–™ï¼Œå³é‚Šç›´æ¥èŠå¤©å•åˆ†æã€‚")


# -----------------------------
# Main: Chat UI
# -----------------------------
st.title("ğŸ’¬ ç›´æ¥å•ï¼ˆä¸­æ–‡èªæ„ç†è§£ + è‡ªå‹•æ‰¾è¡¨ + åˆ†æåœ–è¡¨ï¼‰")

if not st.session_state.dfs:
    st.stop()

# Render history
for m in st.session_state.messages:
    with st.chat_message(m["role"]):
        st.markdown(m["content"])
        # tables
        if m.get("tables"):
            for name, df in m["tables"].items():
                st.write(f"**{name}**")
                st.dataframe(df, use_container_width=True)
        # plotly
        if m.get("plotly_json"):
            try:
                import plotly.io as pio
                fig = pio.from_json(m["plotly_json"])
                st.plotly_chart(fig, use_container_width=True)
            except Exception:
                st.info("åœ–è¡¨è§£æå¤±æ•—ï¼ˆJSON ä»åœ¨ï¼‰")

prompt = st.chat_input("ä¾‹å¦‚ï¼šåˆ†æ 2023 éŠ·è²¨ç¸½é‡èˆ‡ç¸½æœªç¨…é‡‘é¡ï¼Œåšæ¯æœˆè¶¨å‹¢ï¼ˆé›™è»¸ï¼‰ï¼Œåˆ—ç”¢å“TOP10èˆ‡æ¥­å‹™TOP10")

if prompt:
    # User message
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # Assistant processing
    with st.chat_message("assistant"):
        with st.spinner("åˆ†æä¸­..."):
            profiles = st.session_state.profiles
            dfs_all = st.session_state.dfs

            selected_keys = pick_tables(prompt, profiles, topk=TOPK_TABLES)
            tables_json = tables_context_json(selected_keys, profiles)
            dfs_subset = {k: dfs_all[k] for k in selected_keys if k in dfs_all}

            # 1) Get code with retries
            code, logs = get_python_code_with_retries(client, DEFAULT_MODEL, prompt, tables_json)

            # 2) If still empty => fallback
            if not code.strip():
                final_answer, result_tables, plotly_json = fallback_answer(dfs_all, selected_keys)
                st.markdown(final_answer)
                for name, df in result_tables.items():
                    st.write(f"**{name}**")
                    st.dataframe(df, use_container_width=True)
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": final_answer,
                    "tables": result_tables,
                    "plotly_json": plotly_json,
                })
                st.stop()

            # 3) Run sandbox
            res = run_sandbox(code, dfs_subset, timeout_sec=SANDBOX_TIMEOUT)

            # 4) Auto-fix if sandbox fails OR empty outputs
            if (not res.get("ok", False)) or (not (res.get("final_answer") or "").strip() and (res.get("tables") or {})):
                err = res.get("stderr", "")
                feedback = f"""
âš ï¸ ä½ ä¸Šä¸€è¼ªçš„ç¨‹å¼ç¢¼åŸ·è¡Œå¤±æ•—æˆ–è¼¸å‡ºç‚ºç©ºã€‚
éŒ¯èª¤è³‡è¨Š/ç‹€æ³å¦‚ä¸‹ï¼š
{err[:1500]}

è«‹ä½ ä¿®æ­£ç¨‹å¼ç¢¼ï¼Œç¢ºä¿ä¸€å®šè¨­å®š final_answerï¼ˆéç©ºå­—ä¸²ï¼‰èˆ‡ result_tablesï¼ˆè‡³å°‘ 1 å¼µ DataFrameï¼‰ï¼Œå¿…è¦æ™‚å¯ä¸ç•«åœ–ï¼ˆresult_plotly_json=Noneï¼‰ã€‚
ä»è«‹åªè¼¸å‡º JSONï¼š{{"python_code": "..."}}
"""
                # one repair attempt
                raw2 = llm_get_code_json(client, DEFAULT_MODEL, prompt, tables_json, extra_feedback=feedback)
                obj2 = extract_json_object(raw2) or {}
                code2 = (obj2.get("python_code") or "").strip()

                if code2:
                    res2 = run_sandbox(code2, dfs_subset, timeout_sec=SANDBOX_TIMEOUT)
                    if res2.get("ok", False) and ((res2.get("final_answer") or "").strip() or (res2.get("tables") or {})):
                        res = res2

            # 5) Final render (never empty)
            final_answer = (res.get("final_answer") or "").strip()
            tables_json_map = res.get("tables") or {}
            plotly_json = res.get("plotly_json")

            result_tables: Dict[str, pd.DataFrame] = {}

            # decode tables
            for name, df_json in tables_json_map.items():
                try:
                    df_out = pd.read_json(io.StringIO(df_json), orient="records", dtype=False)
                    # if Month exists, rename to å¹´æœˆ
                    if "Month" in df_out.columns and "å¹´æœˆ" not in df_out.columns:
                        df_out = df_out.rename(columns={"Month": "å¹´æœˆ"})
                    # if "å¹´æœˆ" looks like timestamp digits, keep as string anyway
                    result_tables[str(name)] = df_out
                except Exception:
                    pass

            if not final_answer and not result_tables:
                final_answer, result_tables, plotly_json = fallback_answer(dfs_all, selected_keys)

            # show selected tables hint (small, like GPT tool context)
            st.caption("å·²è‡ªå‹•ä½¿ç”¨è³‡æ–™è¡¨ï¼š\n" + "\n".join([f"- {k}" for k in selected_keys]))

            st.markdown(final_answer if final_answer else "ï¼ˆæœ¬æ¬¡æ²’æœ‰æ–‡å­—çµè«–ï¼Œä½†æˆ‘å·²è¼¸å‡ºè¡¨æ ¼ã€‚ï¼‰")

            for name, df in result_tables.items():
                st.write(f"**{name}**")
                st.dataframe(df, use_container_width=True)

            if plotly_json:
                try:
                    import plotly.io as pio
                    fig = pio.from_json(plotly_json)
                    st.plotly_chart(fig, use_container_width=True)
                except Exception:
                    st.info("åœ–è¡¨è§£æå¤±æ•—ï¼ˆJSON ä»åœ¨ï¼‰")

            # Save to history
            st.session_state.messages.append({
                "role": "assistant",
                "content": final_answer,
                "tables": result_tables,
                "plotly_json": plotly_json,
            })
